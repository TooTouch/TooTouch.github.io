---
title:  "Evaluating Feature Importance Estimates Korean Version(한국어버전)"
categories: 
    - Paper Review
    - XAI
toc: true
---

이번에 리뷰할 논문은 2018년에 나왔고 Google AI 팀에서 연구하였습니다. Interpretable AI에 대한 정량적 평가 방법을 제안합니다.

**Authors**: Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, Been Kim  
**Conference**: NIPS  
**Paper**: [Evaluating Feature Importance Estimates](https://arxiv.org/abs/1806.10758)  
**Year**: 2018  

# 역자의 말

영어를 한글로 변역하면서 변역된 단어가 적절하지 못한 경우 영어를 그대로 적용하였습니다. 부족한 부분이 있을 수 있으니 언제라도 잘못된 정보에 대해서는 comment나 메일을 통해서 지적 부탁드리겠습니다.

wogur379@gmail.com 

# Introduction

해석 가능한 모델에 대한 평가는 반드시 두 가지 요건을 모두 충족해야한다. 첫 번째는 사람에게 의미가 있어야하고 두 번째는 정확해야한다. 만약 모델에 대한 설명이 정확하지 않다면 그에 대한 피해는 많은 비용을 초래할 수 있다. 

DNNs 는 비선형 함수와 수많은 입력값 때문에 변수 중요도를 평가하는 것과 과연 이것이 신뢰할 수 있는 것인지 알기어렵다는 것이 문제였다. 

그럼에도 불구하고 복잡한 모델에 대해서 중요도를 평가하기위해 수많은 연구가 있었다.

[수많은 차원때문에 어렵지만 모든 가능한 관점에서 변수의 영향력을 평가한 연구](https://www.notion.so/7e514e6a9fc74859a1d7cee68e4c4672)

[이미지에 대한 모델의 예측 결과에 영향력을 각 픽셀별로 순위를 매기는 연구](https://www.notion.so/b2200ee0d94c4a75b9e1411574bb6935)

[앙상블 방법을 통해 더 선명한 시각화를 만들어내는 연구](https://www.notion.so/b57b975c534e4febb3f39e7c0586b3ba)

위와 같이 변수에 대한 중요도를 평가하는 방법들은 많지만 과연 이 중요도 또한 신뢰할 수 있는 것이지에 대한 것은 여전히 문제이다. 

때문에 본 논문에서 제안하는 것은 deep neural networks (DNNs) 의 변수 중요도를 정확성을 평가하기위한 방법론이다.

이 방법론은 **ROAR**, **R**em**O**ve **A**nd **R**etrain 이라고한다. 이 방법은 모델의 성능을 가장 하락시키는 것을 중요한 요소로 판단하여 변수 중요도에 대한 대략적인 정확도를 평가한다.

ROAR은 각 이미지에 대해서 중요한 요소로 판단된 부분을 분류모델에 영향을 미치지 않는 상수로 대체하여 다시 학습 후 평가한다. 최종적으로 수정된 데이터로 학습된 모델과 수정되지 않은 데이터로 학습된 모델 두 가지를 서로 비교한다. 이때 각 이미지에 대해서 정확도를 비교하고 정확도가 가장 많이 떨어진 경우 지워진 해당 픽셀이 영향력이 있다고 판단한다.

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1wVGbzfagNN_7k4j4HhzdOJqwmROmdZm-' /><br>
    <i>Figure 1. ROAR 방법에 대한 도식화 1) 해석가능한 방법으로 변수에 대한 중요도를 평가한다. 2) 각 이미지에 대해서 중요도로 나타난 부분을 제거한다. 3) 수정된 이미지로 재학습하여 모델 성능의 저하가 어느정도인지 평가한다. </i>
</p>

여기서 굳이 새로운 모델로 비교하는 이유는 'uninformative'를 고려했기 때문이다. 재학습없이는 모델 성능의 저하가 학습 데이터의 매니폴드 외부에있는 대체된 값 때문인지 아니면 정확성 때문이지 알 수 없기 때문이라고 한다. 

또한 본 논문에서는 정확성 평가를 위해 중요도를 무작위로 선정한 결과와 가장자리를 중요도로 추출한 결과를 대조집단으로서 함께 비교하였다. 이 두 방법을 함께 비교한 이유는 과연 다른 방법들이 이 방법들보다 정확하게 중요도를 나타냈을지를 확인하기 위함이다. 

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1PTuSJuLpnRdPNHRqVFV_dTTMGf3vT7K1' /><br>
    <i>Figure 2. A single ImageNet image modified according to the ROAR framework. 사용 모델은 ResNet-50 이다. 
왼쪽에서부터 base estimators (gradient heatmap (GRAD), Integrated Gradiend (IG), Guided Backpop (GB)), derivative approaches that ensemble a set of estimates (SmoothGrad Integrated Gradients (SG-SQ-IG), SmoothGrad-Squared Integrated Gradients (SG-SQ-IG), VarGrad Integrated Gradients (VAR-IG)) and control variants (random modiﬁcation (RANDOM) and a sobel edge ﬁlter (SOBEL))</i>
</p>

본 논문에서 실험한 데이터는 ImageNet, Food101, Birdsnap이고, 결과는 대략적으로 아래와 같이 설명할 수 있다. 

- 앙상블 방법 없이는 그냥 무작위로 추출한 중요도와 별반 차이없는 결과를 나타냈지만 반대로 말하자면 앙상블 방법을 통한 중요도 추출은 무작위로 추출한 중요도보다 훨씬 더 좋은 결과를 보였다.
- 어떤 앙상블 방법을 사용할지 결정하는 것도 중요하다. SmoothGrad-Squared와 Vargrad 방법은 좋은 결과를 냈지만 Classic SmoothGrad는 단일 방법과 크게 차이가 없었고 연산도 굉장히 많이 필요했다.
- 최종적으로 모든 입력값에 대한 무작위 수정에도 꽤 좋은 성능을 나타냈다. 예를 들어 ImageNet 데이터에 대해서 90%나 무작위로 대체해도 63.53 정도 정확도를 낼 수 있는 모델을 만들 수 있었다. 이러한 결과가 나올 수 있었던 이유는 입력값에 많은 중복이 있었기 때문이라지만 본 논문에서 생각한 기본 추정방법들은 무작위로 추측한 것과 별 차이가 없다.

# Related Work

아래와 같이 해석가능한 방법들은 다양하게 있다. 

[제거하거나 강조하는 방법으로 모델을 해석 가능한 기능의 형태로 제한하는 연구](https://www.notion.so/e9ecfbc398d24e72ad119ff97b5917c9)

[은닉층에서 뉴런들의 역할을 조사하는 연구](https://www.notion.so/5f5743a8c9db44bc84a471e67878281a)

[High level 수준에서 예측결과를 설명하는 연구](https://www.notion.so/High-level-20871d8effbc43b9bf4b58a3ce11d2ae)

변수 중요도에 대해 정확도(correctness)를 측정하는 정확한 방법없이 서로다른 측정방법에 대한 상대적 이점을 비교하는 것은 human study형식으로 순서(ranking)가 사람에게 의미가 있는지 에 대해 질문하는 연구가 종종 있었다. 그러나 신뢰성(trustworthy)에 대한 설명은 같은 설명이라 할지라도 모델에 대해 신뢰성 있게 설명한다고 할 수는 없다. 이미 시스템 내에서의 사람 수준의 신뢰는 모델의 성능과는 별개라는 것을 [Manipulating and Measuring Model Interpretability](https://arxiv.org/abs/1802.07810)에서 나타냈다.

최근에는 해석가능한 방법이 신뢰(reliable)와 의미(meaningful) 둘 다 고려하는지에 대해 평가하기위한 연구도 있었다.

본 논문의 내용과 가장 관련있는 것은 [Evaluating the Visualization of What a Deep Neural Network Has Learned](https://arxiv.org/abs/1509.06321)에서 제안한 수정 기반의 평가 방법과 이후 변경된 방법들이다. 예측 모델이 중요하다고 판단한 부분을 의미없는 값으로 수정하고 얼마나 정확도가 감소하는지 확인하는 방법이다. 

그러나 앞서 말한 방법들과 다른 본 연구의 장점은 수정된 이미지에 대해서 단순히 재평가하는 것이아니라 새롭게 학습을 필요로한다는 것이다. 만약 이 과정이 없다면 앞서 말했던 것처럼 모델의 성능 저하가 대체된 값의 어떤 인위적인 요인때문인지 추정기(estimator)의 대략적인 정확도 때문인지 알 수 없다. 

본 논문에서는 이미지에 대해 중요성으로 평가된 부분에 대한 수정 이외에 어떤한 수정도 하지 않았다. 

# Estimating Input Feature Importance

CNN은 입력값 X에 대해서 출력값 Y가 나오게 하는 함수 F를 학습하는 것이다. 어떤 측정치 **G**는 측정 벡터 **e**를 생성한다.  e_i는 활성화함수인 A의 출력값에 대한 x_i의 중요도를 측정한다.

## Evaluation Methodology

e에 대해서 내림차순으로 정렬을 하고 이런 정렬된 집합 t에 대해서 원본 이미지 x를 아무 정보가 없는 상수 c로 대체한다. 아래와 같은 분포를 만들어 t = [0. : 0.1 : 1](0~1사이의 0.1단위로 변경) 와 측청방법 g 를 바꿔가며 각 분포를 정의한다. 

$$p(y, x^M;t_i,g_i)$$

t가 1일때는 수정을 하나도 하지 않은 상태이고, t가 0일때는 모든 입력값을 상수 c로 대체한 경우이다. 

t가 0~1 사이일때 사전에 영향도의 분포를 모르기 때문에 얼마나 입력값을 대체해야 평가데이터가 변화될지는 알 수 없지만 t 값을 조정하면서 평가데이터의 정확도 변화를 비교할 수는 있다.

ROAR는 앞에서도 언급한 것과 같이 가장 좋은 측정방법 g는 영향력있는 부분을 제외했을때 가장 성능이 떨어지는 것이라는 가정하에 측정치를 평가한다. 

즉, 가장 좋은 측정치 g는 평가데이터의 정확도가 가장 낮은 결과로 나와야한다. 아래와 같이 수식으로 표현할 수 있다.

$$\xi (x^M|g^*) = \min_{g \subset \mathcal{G}} \xi(x^M|g) ,\\ where\ x^M\ is\ the\ modified\ dataset\ given\ the\ estimator\ g\\ and\ \xi(x^M|g)\ is\ the\ test\ set\ accuracy$$

또한 대조군으로 사용한 무작위로 영향도를 뽑은 결과보다 더 낮은 성능을 나타내야한다. 아래와 같이 수식으로 표현할 수 있다.

$$\xi(x^M|g) < \xi(x^M|g^R)$$

## Estimators Considered

본 논문에서 사용한 측청방법들과 모델 구조(ResNet-50)은 오픈소스로 공개되어있다. 그리고 ROAR방법 또한 적용하기 쉽게 함께 공개하였다. 

[google-research/google-research](https://github.com/google-research/google-research/tree/master/interpretability_benchmark)

### BASE ESTOMATORS

1. **Gradients or Sensitivity heatmaps** 은 아래 수식과 같다

    $$e = \frac{\partial{A_n^l}}{\partial{x_i}}$$

2. **Guided Backprop**은 signal 방법 중 하나이다. Signal 방법은 상위 레이어의 활성화함수 A에 영향을 주는 입력값의 패턴을 시각화한다. ReLU에서 0 보다 큰 부분에 대한 미분값을 통해 수정된 역전파방법을 사용하여 계산된다.
3. **Integrated Gradients**은 attribution 방법 중 하나이다. Attribution 방법은 각 입력값으로부터 활성화함수 A의 출력에 영향을 주는 요인을 분해하여 어느 부분이 중요한지 나타내는 방법이다. Attribution 방법은 모든 attribution에 대해 영향이 있는 부분들의 합을 사용한다. 이런 속성을 completeness라고 한다. Integrated Gradient는 비정보적(non-informative) 기준인 x^0와 실제 입력값인 x 사이의 값을 추정하여 보간하는 방법이다. 이 적분(integral)은 x^0와 x 사이에 k개의 작은 간격을 모두 합하여 근사할 수 있다. 아래와 같이 수식으로 표현할 수 있다.
최종 추정값 e는 k와 reference point x^0에 따라 결정되고, 본 논문에서는 k는 25 그리고 reference point로 검정 이미지(black image)를 사용하였다.

    $$e=(x_i-x_i^0)\times\sum_{i=1}^{k}\frac{\partial{f_w}(x^0+\frac{i}{k}(x-x^0))}{\partial{x_i}}\times\frac{1}{k}$$

### DERIVATIVE APPROACHES THAT ENSENBLE A SET OF ESTIMATES

1. **ClASSIC SMOOTHGRAD (SG)** 는 J개의 가우시안 노이즈를 추가한 데이터에 대한 변수 중요도를 평균으로 계산한 것이다. 아래와 같이 수식으로 표현할 수있다.

    $$e = \sum_{i=1}^{J}(g_i({x+\eta},A_n^l)) $$

2. **SMOOTHGRAD^2 (SG-SQ)** 는 발표하진 않았었지만 기존 SG에 평균내기전에 제곱합을 한 방법이다. 

    $$e = \sum_{i=1}^{J}(g_i({x+\eta},A_n^l)^2) $$

3. **VARGRAD (VAR)**은 SG처럼 가우시안 노이즈를 추가한 이미지에 대해 변수 중요도를 구하는 건 똑같지만 평균이 아닌 분산을 구한다. 

$$e=Var(g_i(x+\eta, A_n^l))$$

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1_tmOibWtgoKYqgdguzKUP9GlZy3gBgFN' /><br>
    <i>Figrue 3. Food 101 이미지에 대해서 기본 측정방법인 GRAD와 앙상블 방법인 SmoothGrad Grad, SmoothGrad-Squared Grad, VarGrad Grad의 비교 결과</i>
</p>

### CONTROL VARIANTS

앞서 언급한것과 같이 대조군으로 두 가지 방법을 사용하였다.  **RANDOM** 그리고 **SOBEL EDGE FILTER** 이다.

## The Importance of Training a New Model

수정된 이미지로 모델을 새롭게 훈련시키는 것이 핵심이다. 상수값 c로 대체된 이미지를 학습하게 되면 모델의 성능을 왜곡(distort)하는 인위 구조(artifacts)나 새로운 증거(new evidence)를 얻을 수 있다. 

이게 가능한 것은 어디까지나 상수 c가 X의 분포에는 있는지만 Y를 분류하는데 독립적인 관계이어야한다는 것이다. 

Fig. 5는 수정된 이미지에 대해서 새롭게 훈련한 모델과 훈련하지 않은 모델의 차이를 비교한다. 예를 들면 ImageNet 데이터에 대해서 90%가 변경된 이미지는 기존에 이미 훈련된 모델은 50%까지 성능이 떨어지지만 변경된 데이터에 대해서 학습한 모델은 63.77%까지밖에 떨어지지 않는다. 모델을 재학습 하지 않고서는 변경(modification) 때문에 성능이 하락되었는지 알 수 없기 때문에 해석가능한 방법에 대한 성능을 판별하기가 어렵다. 

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1x98ygqvkNiCfUzxck-Q3YaXd3YJWpkIc' /><br>
    <i>Figure 5. 수정된 이미지에 대해 재학습한(RETRAIN) 모델의 결과 차이와 재학습하지 않은(NO-RETRAIN) 모델의 결과 차이 비교</i>
</p>

# Experimental Framework and Results

## Experiment Framework

ResNet-50을 모델로 사용하였다. 모든 이미지에 대한 전처리는 [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677)의 방법을 사용하였다. 모든 학습이미지와 평가이미지에 대해서 추정값 e를 만들었고, 모든 측정방법들에 대해 활성화 An은 모델 예측을 위해 softmax 를 사용하였다. 계산한 e에 대해서는 순서를 매겼고, 상위 t개에 대해서는 원본 이미지의 각 채널별 평균으로 대체하였다. 

ROAR를 평가하기 위해서는 ImageNet, Birdsnap 그리고 Food 101 데이터를 사용했으며 각 데이터셋과 측정방법에 대해서는 t를 [0.1, 0.3, 0.5, 0.7, 0.9]이고 가장 중요한 픽셀을 제거한 것과 유지한 것으로 해서 총 10개의 새로운 학습데이터와 평가데이터를 사용했다. 기본 측정방법과 앙상블방법 그리고 제곱을 사용한 측정방법들을 포함하여 총 18개의 측정방법을 사용했다. 최종적으로는 총 540개의 이미지 데이터셋을 구축하였고 실험하였다. 

각 이미지에 대해서 서로 독립적인 5개의 ResNet-50 모델을 학습했으며 본 논문에서 나온 평가데이터의 정확도는 5개의 모델의 결과에 대한 평균이다. 수정되지 않은 ImageNet을 학습한 ResNet-50의 정확도는 76.68% 였다. 수정되지 않은 Birdsnap과 Food 101의 정확도는 각각 66.65% 그리고 84.54% 였다(10개의 독립적인 모델의 결과 평균).  

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1NZOKMMjjfgvJKu_J8egi64GhBfLs_nYc' /><br>
    <i>Table 1. The training procedure was carefully finetuned for each dataset. These hyperparameters are consistently used a cross all experiment variants. The baseline accuracy of each unmodiﬁed data set is reported as the average of 10 independent runs.</i>
</p>

## Experimental Results

### ROBUST PERFORMANCE GIVEN RANDOM MODIFICATION

$$The\ estimator\ g^R\ assigns\ importance\ at\ random\ to\ all\ inputs.$$

무작위 방법을 baseline으로 하여 측정방법들을 비교하는 것은 적어도 측정방법들이 baseline보다 잘나와야 한다는 기준이 될 수 있다. 랜점 baseline의 성능은 생각보다 놀랍고 모든 데이터에 대해서 일관성이 있었다. 예를 들면 ImageNet 데이터에 대해서 단지 10%만 남아있어도 학습된 모델은 여전히 63.53%의 정확도를 보였다. 

입력값의 작은 랜덤부분으로부터 의미있는 결과를 낸 모델의 성능이 많은 입력값들이 중복되어 있을 가능성이 있다는 것을 나타낸다. 이는 본 논문에서 사용한 이미지가 픽셀간 상관관계가 예상이 되기 때문일 것이라고 생각한다. 즉, 픽셀간 상관관계가 높기때문에 작은 부분만 가지고도 어느정도 이미지에 대해서 추론이 가능한 것 같다고 본다.

### ROAR: BASE ESTIMATORS NO BETTER THAN A RANDOM GUESS WHEN RETRAINING

놀랍게도 Fig. 4의 왼쪽 열을 보면 기본 측정방법으로 사용한 (GB, IG, GRAD) 모두 모든 데이터셋에 대해서 대조군보다 더 결과가 좋지 않았다. 그 차이는 t가 0.9 일때 더 커진다. 이 결과는 대조군은 모델 파라미터와는 완전 독립적이기 때문에 의미가 있다. 그러나 반대로 기본 측정방법들은 모델 가중치와 의존적이다. 그렇기 때문에 이 방법들이 대조군보다 더 나은 성능을 나타내길 기대한다.

기존 측정방법들은 모두 변화의 폭이 좁다. 각각 다른 방법(formulation)임에도 불구하고 별차이가 없다. Birdsnap의 경우 가 t가 0.9 일때 가장 높은 것와 낮은 것의 차이가 4.22% 밖에 나지 않았고, Food101과 ImageNet에 대해서는 각각 5.17%와 3.62% 밖에 나지 않았다. 

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1ySkvbwQmlG3vDGOvhFC_buQ2gMXses6F' /><br>
    <i>Figure 4. 왼쪽은 기본 측정방법들 (GRAD, IG, GB). 가운데는 SG를 적용한 것. 오른쪽은 SG-SQ + VAR를 적용한 것</i>
</p>

### ROAR: ENSEMBLE APPROACHES ARE NOT CREATED EQUAL

앙상블 방법을 적용하기 위해 연산량이 늘어나는 것은 불가피하다. 시각적으로 보이는 노이즈를 줄이기 위해 해석가능한 방법으로 앙상블이 종종 사용된다. 그러나 이 방법이 실제로 무슨일을 하는지 설명의 정확성과 얼마나 연관이 있는지 이해하는 경우는 별로 없다. 때문에 본 논문에서 세 가지 앙상블 방법(SG, SG-SQ 그리고 VAR)을 적용하여 장단점을 파악한다. 

**Classic SmoothGrad is less accurate or on par with a single estimate**
Class SmoothGrad는 단일 방법과 큰 차이가 나지 않았다. Fig. 4의 중간 열이 SG를 적용한 결과이다. 더 많은 연산량을 들어서 비교했음에도 불구하고 결과는 큰 차이가 나지 않았고, 몇몇 결과에서는 단일방법보다 더 안좋은 결과를 내었다. 

**SmoothGrad-Squared produced large gains in accuracy**
SmoothGrad-Squared는 더 좋은 결과를 내었다. SG와는 달리 대조군과 큰 차이는 내었고, 모든 측정방법들과 데이터셋에 대해서 일관된 결과를 보였다. 

**Squaring Slightly Improves the Performance of All Base Variants**
SG와 SG-SQ의 차이는 평균내기전에 제곱을 해주었다는 것 뿐이다. Fig. 8은 앙상블이 아닌 단순히 제곱만 하여 그차이가 어떤지 비교해보았다. 그 결과 제곱자체로 더 좋은 결과는 낼 수 있었지만 제곱만으로는 SG-SQ만큼의 정확도 차이는 설명할 수는 없었다.

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=1rPUjOPEs6jh7xyWXXhjF7oLjOhQIrD17' /><br>
    <i>Figure 8. 제곱의 영향을 확인하기 위한 실험.</i>
</p> 

**VarGrad is comparable in performance to SmoothGrad-Squared**
Fig. 4 오른쪽 열을 보면 VAR과 SG-SQ는 두 대조군보다 훨씬 더 좋은 결과를 내었다. 게다가 이 두 방법은 단일방법으로도 더 좋은 결과를 낸다. 

그러나 두 방법이 모든 기본 측정방법들보다 좋은 결과를 내지만 데이터마다 약간씩 차이가 있다. ImageNet와 Food101의 경우 gradient heatmap (GRAD)에 사용할 때 가장 좋았고, Birdsnap의 경우 Guided Barkprop (GB)에 사용할 때 가장 좋았다. 앙상블 방법이 성능을 올리는 건 어느 데이터에나 해당되지만 가장 좋은 측정방법을 선택하는 건 어떤 도메인(task)인가에 따라 달렸다. 

VAR과 SG-SQ가 모두 좋은 결과를 낼 수 있는 것은 두 방법이 서로 비슷하기 때문이다. 아래 수식으로 보면 평균이 0에 가까운수록 VAR과 SG-SQ가 비슷해지는 것을 알 수 있다.

$$\bar{e}=\frac{1}{J}\sum_{i=1}^{J}g_i(x+\eta, A_n^l) \\ \hat{e}=\sum_{i=1}^{J}(g_i(x+\eta, A_n^l)-\bar{e})^2$$

# Conclusion and Future work

본 논문을 통해 해석가능한 방법들을 평가할 수 있는 ROAR를 제안했다. 결과는 대조군으로 무작위 방법과 가장자리만 사용한 방법을 사용했고, 단일 방법은 모두 대조군보다 안좋은 결과를 나타냈고 앙상블 방법은 그와 반대로 연산량은 늘어났지만 단일 방법보다 더 좋은 결과를 내었다. 단, SmoothGrad-Squared와 VarGrad만 해당하고 SmoothGrad 방법은 제외이다. 본 연구에서는 왜 앙상블 방법들이 더 좋은 결과를 낼 수 있었는지는 잠시 고려해보았지만 그 방법간의 차이가 나는지에 대해서는 후속 연구로 해볼 만 하다. 

# A. Supplementary Charts and Experiments

## A.3 Evaluating Keeping Rather Than Removing Information

ROAR 방법이 아닌 유지하는 방법으로 **KAR**, **K**eep **A**nd **R**etrain 도 같이 실험해 보았다. KAR은 ROAR와 반대로 중요한 부분만 유지하는 것이다. 그 결과로는 평가데이터에 대해 정확도가 덜 저하될 수록 좋다. 

Fig. 7은 그 실험에 대한 결과이다. 결과적으로 단일 방법이나 앙상블 방법이나 모두 별 차이가 없었고 성능 또한 모두 크게 저하되지 않았다.

<p align="center">
    <img src='http://drive.google.com/uc?export=view&id=175kbM40VLy_OLWdnWqT5A-fbe3501Tkp' /><br>
    <i>Figure 7. 모든 측정방법에 대한 KAR vs ROAR의 평가 비교</i>
</p> 

## A.4. Squaring Alone Slightly Improves the Performance of All Base Variants

Fig. 8의 결과와 같이 단순히 제곱만 하는 것으로 결과가 더 좋아짐을 알 수 있었다. 이 결과는 제곱한 것이 어떤 영향을 나타내는지 확인해야하는데, 제곱하는 것은 절대값을 씌우는 것과 같은 변형을 준다. 제곱을 하게되면 모든 음수값을 양수로 변환한다. 그리고 이 결과에 대한 순서는 방향성이 아닌 규모에 따라 정해진다. GB, IG 그리고 GRAD 모두 모델의 가중치를 반영한다. 규모는 방향보다 변수의 중요도를 더 잘 나타낼 수 있고, 음수값 또한 양수값과 마찬가지로 모델 예측을 위해 중요하다. 그러나 제곱하는 것이 성능을 더 향상시키는 것은 맞지만 이 변형(transformation)이 제곱합의 평균만큼이나 큰 결과의 차이는 나타내는 것을 설명할 수는 없다.