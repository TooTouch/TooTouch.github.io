---
title:  "6.4 Influential Instances"
permalink: /IML/influential_instances/
toc: true
---

# Influential Instances


<!-- Intro text -->
기계 학습 모델은 궁극적으로 교육 데이터의 산물이며 교육 인스턴스 중 하나를 삭제하면 결과 모델에 영향을 미칠 수 있습니다.
교육 데이터가 교육 데이터에서 삭제되면 모델의 매개변수 또는 예측이 크게 변경될 때 교육 인스턴스를 "유연성"이라고 부릅니다.
영향력 있는 교육 인스턴스를 식별함으로써, 우리는 기계 학습 모델을 "debug"하고 그들의 행동과 예측을 더 잘 설명할 수 있습니다.


<!-- *Keywords: Influential instances, influence function, leave-one-out analysis, Cook's distance, deletion diagnostics, robust statistics* -->


이 장에서는 영향력 있는 인스턴스(instance)를 식별하기 위한 두 가지 방법, 즉 삭제 진단 및 영향 기능을 보여 줍니다.
두 접근방식은 모두 견실한 통계를 기반으로 하며, 이는 특이치 또는 모델 가정 위반의 영향을 덜 받는 통계적 방법을 제공합니다.
또한 강력한 통계는 데이터의 추정치가 얼마나 견고한지 측정하는 방법(예: 평균 추정치 또는 예측 모델의 가중치)을 제공합니다.

여러분이 도시에 사는 사람들의 평균 수입을 추산하고 거리에 있는 10명의 무작위 사람들에게 그들이 얼마나 벌 수 있는지 물어보고 싶다고 상상해 보세요.
표본이 정말 형편없다는 사실 외에도, 평균 소득 추정치는 한 사람의 영향을 얼마나 받을 수 있을까요?
이 질문에 답하기 위해, 개별 답변을 생략하거나 "인플레이션 함수"를 통해 평균값이 어떻게 영향을 받을 수 있는지 수학적으로 도출하여 평균값을 재계산할 수 있습니다.
삭제 접근법을 사용하면 평균값을 10회 재계산하여 매번 소득명세서 중 하나를 생략하고 평균 추정치가 얼마나 변하는지 측정합니다.
큰 변화는 한 예가 매우 영향력이 있었다는 것을 의미합니다.
두 번째 접근 방식은 통계 또는 모델의 첫 번째 파생 모델 계산에 해당하는 극히 작은 무게로 사람 중 하나를 가중시킵니다.
이러한 접근 방식은 "infinitimal approach" 또는 "인플레이션 함수"라고도 합니다.
답은 평균이 단일 값으로 선형적으로 확장되기 때문에 평균 추정치가 단일 답에 의해 매우 강하게 영향을 받을 수 있다는 것입니다.
표본에서 소득이 가장 높은 사람이 10배 더 많이 벌어도 결과 중위수는 변경되지 않기 때문에 더 강력한 선택은 중위수(인구의 절반은 더 많이 벌고 나머지 절반은 덜 버는 값)입니다.

삭제 진단 및 영향 기능은 기계 학습 모델의 매개변수 또는 예측에도 적용하여 동작을 더 잘 이해하거나 개별 예측을 설명할 수 있습니다.
영향력 있는 인스턴스를 찾기 위한 이 두 가지 접근 방식을 살펴보기 전에, 특이치 및 영향력 있는 인스턴스 간의 차이를 검토하겠습니다.

**이상치**

특이치란 데이터 세트의 다른 인스턴스와 멀리 떨어져 있는 인스턴스입니다.
"멀리 떨어져 있다"는 것은 다른 모든 경우에 대한 유클리드 거리 같은 거리가 매우 크다는 것을 의미합니다.
신생아의 데이터 세트에서는 6kg의 신생아가 특이치입니다.
당좌예금 계정이 대부분인 은행 계좌의 데이터 세트에서는 전용 대출 계정(대규모 마이너스 잔액, 거래 횟수)이 특례로 간주됩니다.
다음 그림은 1차원 분포의 특이치입니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/outlier-1.png'><br>
    <i>그림 6.14: 형상 x는 x=8의 특이치로 가우스 분포를 따릅니다.</i>
</p>

특이치는 흥미로운 데이터 포인트(예: [비판](#proto))일 수 있습니다.
특이치기가 모델에 영향을 미치는 경우 또한 영향력 있는 인스턴스이다.

**영향을 미치는 관측치**

영향력 있는 인스턴스는 데이터 인스턴스이며, 데이터 인스턴스는 제거가 교육된 모델에 큰 영향을 미칩니다.
교육 데이터에서 특정 인스턴스를 제거한 상태에서 모델을 재교육할 때 모델 매개 변수나 예측이 더 많이 변경될수록 해당 인스턴스의 영향력이 더 커집니다. 인스턴스(instance)가 훈련된 모델에 영향을 미치는지 여부는 대상 y에 대한 해당 값에 따라 달라집니다.
다음 그림은 선형 회귀 모형의 영향력 있는 인스턴스를 보여 줍니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/influential-point-1.png'><br>
    <i>그림 6.15: 하나의 형상을 가진 선형 모형입니다. 영향력 있는 인스턴스 없이 전체 데이터에 대해 한 번 교육받습니다. 영향력 있는 인스턴스를 제거하면 적합 경사(가중/계수)가 크게 변경됩니다.</i>
</p>


**유효한 인스턴스가 모델을 이해하는 데 도움이 되는 이유는 무엇입니까?**

해석 가능성을 위한 영향력 있는 사례의 핵심 아이디어는 모델 매개변수와 예측을 모든 것이 시작된 위치, 즉 교육 데이터를 추적하는 것입니다.
학습자, 즉 기계 학습 모델을 생성하는 알고리즘은 기능 X와 대상 y로 구성된 교육 데이터를 가져와서 기계 학습 모델을 생성하는 기능입니다.
예를 들어 의사결정 트리의 학습자는 분할 피쳐와 분할할 값을 선택하는 알고리즘입니다.
신경 네트워크의 학습자는 백프로포지션을 사용하여 최적의 가중치를 찾습니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/learner.png'><br>
    <i>그림 6.16: 학습자는 교육 데이터에서 모델을 학습합니다(기능과 대상). 모델은 새 데이터를 예측합니다.</i>
</p>

교육 프로세스에서 교육 데이터에서 인스턴스를 제거할 경우 모델 매개 변수나 예측이 어떻게 변경되는지 묻습니다.
이는 [부분 의존도 그림](#pdp) 또는 [특성 중요도](#feature-importance)와 같이 예측되는 인스턴스의 특징을 조작할 때 예측이 어떻게 변화하는지 분석하는 다른 해석성 접근 방식과는 대조적입니다.
영향력 있는 사례에서는 모델을 고정된 것으로 취급하지 않고 교육 데이터의 함수로 취급합니다.
영향력 있는 인스턴스는 글로벌 모델 동작 및 개별 예측에 대한 질문에 답변하는 데 도움이 됩니다.
모델 매개변수 또는 예측에 전체적으로 가장 영향을 미친 예는 무엇입니까?
어떤 예가 특정 예측에 가장 영향을 미쳤습니까?
영향력 있는 인스턴스는 모델에 문제가 있을 수 있는 인스턴스를 알려줍니다. 어떤 교육 인스턴스에 오류가 있는지 확인하고 모델의 견고함을 보여 줍니다.
단일 인스턴스가 모델 예측 및 매개변수에 강력한 영향을 미치는 경우 모델을 신뢰하지 않을 수 있습니다.
적어도 그렇게 되면 우리는 더 많은 조사를 받게 될 것입니다.

어떻게 하면 영향력 있는 사례를 찾을 수 있을까요?
영향력을 측정하는 방법은 두 가지가 있습니다.
첫 번째 옵션은 교육 데이터에서 인스턴스를 삭제하고, 줄어든 교육 데이터 세트에 모델을 재교육하고, 모델 파라미터 또는 예측의 차이(개별적으로 또는 전체 데이터 세트에 걸쳐)를 관찰하는 것입니다.
두 번째 옵션은 모델 매개변수의 기울기를 기준으로 매개변수 변경사항을 근사하여 데이터 인스턴스(instance)의 가중치를 높이는 것입니다.
삭제 접근법은 이해하기 쉽고 상승 접근방식에 동기를 부여하므로, 먼저 이전 접근방식으로 시작합니다.

# Deletion Diagnostics

통계학자들은 이미 영향력 있는 사례, 특히 (일반화된) 선형 회귀 모형에 대해 많은 연구를 수행했습니다.
"인플루엔자 관측치"를 검색할 때 첫 번째 검색 결과는 DFBETA 및 Cook의 거리와 같은 측정치에 대한 것입니다.
**DFBETA**는 모델 매개 변수의 인스턴스 삭제 효과를 측정합니다.
**Cook의 거리***(Cook, 1977[^1])는 모델 예측에 대한 인스턴스 삭제 효과를 측정합니다.
두 가지 조치 모두 매번 개별 인스턴스를 생략한 채 반복적으로 모델을 재교육해야 합니다.
모든 인스턴스가 포함된 모델의 파라미터 또는 예측을 교육 데이터에서 삭제된 인스턴스 중 하나와 비교합니다.

$$DFBETA_{i}=\beta-\beta^{(-i)}$$

여기서 $\beta$는 모델이 모든 데이터 인스턴스에 대해 교육될 때 가중치 벡터이고 $\beta^{(-i)}$ 모델은 인스턴스 i 없이 교육될 때 가중치 벡터입니다.
꽤 직관적인데요.
DFBETA는 로지스틱 회귀 분석 또는 신경 네트워크와 같은 가중치 파라미터가 있는 모델에만 작동하지만 의사 결정 트리, 트리 앙상블, 일부 지원 벡터 시스템 등의 모델에는 작동하지 않습니다.

쿡의 거리는 선형 회귀 모형에 대해 발명되었으며 일반화된 선형 회귀 모형에 대한 근사치가 존재합니다.
교육 인스턴스에 대한 쿡의 거리는 i번째 인스턴스가 모델 교육에서 제거될 때 예측된 결과의 제곱 차이(척도)의 합으로 정의됩니다.

$$D_i=\frac{\sum_{j=1}^n(\hat{y}_j-\hat{y}_{j}^{(-i)})^2}{p\cdot{}MSE}$$

여기서 분자는 데이터 집합을 통해 요약된 i번째 인스턴스(instance)가 있는 모형과 없는 모형의 예측 간의 제곱 차이입니다.
분모는 평균 제곱 오차에 대한 피쳐의 수입니다.
분모는 어떤 인스턴스(instance)를 제거하든 모든 인스턴스에 대해 동일합니다.
Cook의 거리는 교육에서 i번째 인스턴스를 제거할 때 선형 모델의 예상 출력이 얼마나 변하는지 알려줍니다.


기계 학습 모델에는 쿡의 거리와 DFBETA를 사용할 수 있습니까?
DFBETA에는 모델 매개 변수가 필요하므로 이 측정은 매개 변수화된 모델에 대해서만 적용됩니다.
Cook의 거리에는 모델 파라미터가 필요하지 않습니다.
흥미롭게도, 쿡의 거리는 보통 선형 모델과 일반화된 선형 모델의 맥락 밖에서 볼 수 없지만, 특정 인스턴스를 제거하기 전과 제거한 후의 모델 예측 간의 차이를 고려한다는 생각은 매우 일반적입니다.
Cook의 거리 정의에 문제가 있는 것은 MSE이며, 이는 모든 유형의 예측 모델(예: 분류)에 의미가 없다.

모델 예측에 미치는 영향에 대한 가장 간단한 영향 측정은 다음과 같이 작성할 수 있습니다.

$$\text{Influence}^{(-i)}=\frac{1}{n}\sum_{j=1}^{n}\left|\hat{y}_j-\hat{y}_{j}^{(-i)}\right|$$

이 식은 기본적으로 Cook의 거리의 분자로, 절대 차이가 제곱된 차이 대신 합산된다는 차이입니다.
이것은 제가 선택한 것입니다. 왜냐하면 그것은 나중에 예시들을 위해 합당하기 때문입니다.
일반적인 형태의 삭제 진단 측정은 측정값(예: 예측된 결과)을 선택하고 모든 인스턴스에서 교육된 모형에 대한 측정값의 차이를 계산하는 것으로 구성됩니다.


예를 들어 i번째 교육 인스턴스의 영향이 무엇이었는지를 예측하기 위해 영향을 쉽게 분해할 수 있습니다.

$$\text{Influence}_{j}^{(-i)}=\left|\hat{y}_j-\hat{y}_{j}^{(-i)}\right|$$

또한 모델 파라미터의 차이 또는 손실 차이에도 효과가 있습니다.
다음 예에서는 이러한 간단한 영향 조치를 사용할 것입니다.

**Deletion diagnostics example**

다음 예에서, 우리는 위험 요인을 감안하여 [임상암](#cervical)을 예측하고 어떤 훈련 사례가 전체적으로 가장 영향을 미쳤는지 측정하도록 지원 벡터 기계를 교육합니다.
암의 예측은 분류상의 문제이기 때문에, 그 영향을 암의 예측 확률의 차이로 측정한다.
모델 교육에서 인스턴스를 제거할 때 예측된 확률이 평균적으로 데이터 집합에서 강하게 증가하거나 감소하는 경우에 한 예가 영향을 미칩니다.
모든 'r nrow(cervical)' 교육 인스턴스에 대한 영향을 측정하려면 모든 데이터에 대해 한 번 교육하고 매번 제거된 인스턴스 중 하나를 사용하여 'r nrow(cervical)' 시간(= size of training data)을 재교육해야 합니다.

가장 영향력 있는 사례는 r sprintf("%.2f", bat(df[1"인플레이션")의 영향도이다.
r sprintf('%.2f'), bat(df[1', 인플레이스])의 영향이란 r df$id[1]를 제거하면 예측 확률은 평균 r sprintf('%.0f', 100 * df[1', 인플레이스])의 비율로 변한다는 의미이다.
이는 암 발생 확률을 평균 r 스프린트f('%.1f', 100 *mean(예측.origin)%로 봤을 때 상당한 수치이다.
가능한 모든 삭제에 대한 영향 조치의 평균 가치는 "r sprintf('%.1f', 100 * 평균(abs(df$flluence)))" 백분율입니다.
이제 어떤 데이터 인스턴스가 모델에 가장 큰 영향을 미쳤는지 알게 되었습니다.
이 기능은 이미 데이터를 디버깅하는 데 유용합니다.
문제가 있는 사례가 있습니까?
측정 오류가 있습니까?
영향력 있는 인스턴스(instance)는 오류의 각 오류가 모델 예측에 큰 영향을 미치기 때문에 오류를 먼저 검사해야 하는 인스턴스입니다.

모델 디버깅 외에도 모델을 더 잘 이해할 수 있는 방법을 배울 수 있을까요?
가장 영향력 있는 상위 10개 인스턴스를 인쇄하는 것만으로는 별로 유용하지 않습니다. 왜냐하면 여러 기능을 가진 인스턴스의 표에 불과하기 때문입니다.
인스턴스를 출력으로 반환하는 모든 방법은 해당 인스턴스를 나타내는 좋은 방법이 있을 경우에만 의미가 있습니다.
그러나 우리는 다음과 같은 질문을 할 때 어떤 종류의 인스턴스가 영향을 미치는지 더 잘 이해할 수 있습니다.
영향력 있는 인스턴스와 비인플레이션 인스턴스의 차이점은 무엇입니까?
이 질문을 회귀 분석 문제로 변환하고 인스턴스(instance)의 영향을 형상 값의 함수로 모형화할 수 있습니다.
[Interprintable Machine Learning Models](#simple)의 장에서 아무 모델이나 자유롭게 선택할 수 있습니다.
이 예에서는 35세 이상 여성의 데이터가 지원 벡터 기계에 가장 큰 영향을 미친다는 것을 보여주는 의사결정 트리를 선택했습니다.
데이터 집합의 모든 여성 중 'rsum(cervical$)'을 선택합니다.‘r nrow’ 중 나이 >=35)는 35세 이상이었다.
[부분 의존도 그림](#pdp)의 장에서는 40세 이후에는 암의 예측 확률이 급격히 증가하며 [특성 중요도](#feature-importance)도 가장 중요한 특징 중 하나로 나이를 감지하는 것을 보았습니다.
영향 분석 결과, 고령의 암 예측 시 모델이 점점 불안정해진다는 것을 알 수
이것 자체가 귀중한 정보이다.
즉, 이러한 인스턴스의 오류는 모델에 큰 영향을 미칠 수 있습니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/cooks-analyzed-1.png'><br>
    <i>그림 6.17: 인스턴스의 영향과 해당 기능 간의 관계를 모델링하는 의사결정 트리입니다. 트리의 최대 깊이는 2로 설정됩니다.</i>
</p>


이 첫 번째 영향 분석에서는 *전체*개의 가장 영향력 있는 인스턴스가 나타났습니다.
이제 가장 영향력 있는 교육 데이터 인스턴스를 찾아 예측에 대해 설명하고자 하는 "r i번째 인스턴스" 중 하나를 선택합니다.
이는 반사실적 질문과도 같습니다.
교육 과정에서 예시 i를 생략할 경우 예시 결과는 어떻게 변경됩니까?
모든 경우에 대해 이 제거를 반복합니다.
그런 다음 교육에서 누락된 예시 r i의 예측에 가장 큰 변화를 가져오는 교육 인스턴스를 선택하여 해당 예시 모델의 예측을 설명합니다.
예를 들어 ‘r i’의 예측을 설명하기로 한 것은 암 발생 확률을 가장 높게 예측한 예(r sprintf('%.2f, 100 * from.i)%)이기 때문인데, 좀 더 깊이 분석하는 것은 흥미로운 경우라고 생각했다.
예를 들어 표로 인쇄된 r i번째 인스턴스를 예측하는 데 가장 영향력 있는 10가지 인스턴스를 반환할 수 있습니다.
별로 쓸모가 없어요. 왜냐하면 우리는 많은 것을 볼 수 없었거든요.
다시 말해, 영향력 있는 인스턴스의 특징을 분석하여 영향력 있는 인스턴스와 비인플레이션 인스턴스를 구별하는 것이 무엇인지 알아내는 것이 더 이치에 맞습니다.
우리는 주어진 특징에 따라 영향을 예측하기 위해 훈련된 의사결정 트리를 사용하지만, 실제로는 단지 구조를 찾고 실제로 무언가를 예측하지 않기 위해 그것을 오용합니다.
다음 의사결정 트리는 r i번째 예를 예측하는 데 가장 큰 영향을 미친 교육 사례를 보여줍니다.


<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/influence-single-1.png'><br>
    <i>그림 6.18: 7번째 인스턴스를 예측하는 데 가장 큰 영향을 미친 인스턴스를 설명하는 의사 결정 트리입니다. 18.5년 이상 담배를 피운 여성의 데이터는 7번째 경우의 예측에 큰 영향을 미쳤고, 암 발생 확률은 평균 11.7% 포인트나 됩니다.</i>
</p>

18.5년 이상 담배를 피웠거나 담배를 피운 여성의 데이터 사례는 'r i'번째 사례'의 예측에 큰 영향을 미칩니다.
'r i'의 배후에 있는 여성은 'r cypical$smokes'를 위해 담배를 피웠습니다.몇 년입니다.
데이터에서 'rsum(cervical$smokes)'을 선택합니다.연도 >=18.5)의 여성들("r sprintf('%.2f', 100 *(cervical$smokes)연도 >= 18.5)"%) 흡연 연도 18.5세 이상입니다.
이 여성들 중 한 명의 흡연 연수를 수집하는 과정에서 발생한 실수는 'r i'번째 예에서 예상되는 결과에 큰 영향을 미칠 것입니다.

인스턴스 번호 'rest.case.index'를 제거할 때 예측에 가장 큰 변화가 발생합니다.
그 환자는 'r courchemokes'를 위해 담배를 피웠다고 합니다.몇 년.[최악의.case.index] 년도이며, 의사결정 나무의 결과와 일치한다.
r i번째 인스턴스의 예상 확률은 r 스프린트f(%.2f), 100 * 예측.orige[i]%에서 r 스프린트f(%.2f), 100 *(예상.i[i] - cypical.200$ 인플레이스]%로 바뀝니다.


가장 영향력 있는 인스턴스의 특징을 자세히 살펴보면, 또 다른 가능한 문제를 볼 수 있습니다.
자료에 따르면 이 여성은 28세이며 22년째 담배를 피우고 있다고 한다.
그것은 정말 극단적인 경우이고 그녀는 정말로 6살에 담배를 피우기 시작했거나 아니면 이것은 데이터 오류이다.
저는 후자를 믿는 경향이 있어요.
이것은 확실히 우리가 데이터의 정확성에 의문을 제기해야 하는 상황입니다.

이 예제에서는 모델을 디버깅하기 위한 영향력 있는 인스턴스를 식별하는 것이 얼마나 유용한지를 보여 주었습니다.
제안된 접근 방식의 한 가지 문제는 각 교육 인스턴스에 대해 모델을 재교육해야 한다는 것입니다.
수천 개의 교육 인스턴스를 보유한 경우 모델을 수천 번 재교육해야 하기 때문에 전체 재교육이 상당히 느릴 수 있습니다.
이 모델을 교육하는 데 하루가 걸리고 1000개의 교육 인스턴스가 있다고 가정하면, 영향력 있는 인스턴스(instance)를 병렬화하지 않고 계산하는 데 거의 3년이 걸릴 것입니다.
아무도 이럴 시간이 없어요
이 장의 나머지 부분에서는 모델을 재교육할 필요가 없는 방법을 보여드리겠습니다.


# Influence Functions

*You*: 교육 인스턴스가 특정 예측에 미치는 영향을 알고 싶습니다.
*연구*: 교육 인스턴스를 삭제하고 모델을 재교육하고 예측의 차이를 측정할 수 있습니다.
*당신*: 좋아요! 하지만 재교육 없이 작동하는 방법이 있나요? 시간이 너무 많이 걸려요.
*연구*: 모수 대비 두 배 차이가 나는 손실 기능이 있는 모델이 있습니까?
*당신*: 저는 로지스틱 손실과 함께 신경망을 훈련시켰습니다. 네, 그렇습니다.
*연구*: 그런 다음 모델 파라미터 및 예측에 대한 인스턴스의 영향을 **인플레이션 기능*을 사용하여 대략적으로 파악할 수 있습니다.
영향 함수는 모델 매개변수 또는 예측이 교육 인스턴스에 얼마나 강하게 의존하는지를 나타내는 척도이다.
메서드는 인스턴스를 삭제하는 대신 손실 시 인스턴스를 매우 작은 단계만큼 가중시킵니다.
이 방법에는 그라데이션 및 헤시안 매트릭스를 사용하여 현재 모델 매개변수 주위의 손실 근사치가 포함됩니다.
손실 상승 가중치는 인스턴스를 삭제하는 것과 유사합니다.
*당신*:좋아요, 그게 제가 찾고 있는 거예요!

Koh와 Liang(2017)[^2]은 인스턴스가 모델 매개변수 또는 예측에 어떤 영향을 미치는지 측정하기 위해 강력한 통계 방법인 영향 함수를 사용할 것을 제안했습니다.
삭제 진단과 마찬가지로 영향 기능은 모델 매개 변수와 예측을 담당 교육 인스턴스로 다시 추적합니다.
그러나 이 방법은 교육 인스턴스를 삭제하는 대신 경험적 위험(교육 데이터에 대한 손실 합계)에서 인스턴스(instance)가 상승할 때 모델이 얼마나 변하는지 대략적으로 보여줍니다.

영향 함수의 방법은 모델 매개변수에 대한 손실 경사에 액세스해야 하며, 이는 기계 학습 모델의 하위 집합에서만 작동합니다.
로지스틱 회귀 분석, 신경망 및 지원 벡터 기계는 랜덤 포리스트와 같은 트리 기반 방법이 적합합니다.
영향 기능은 모델 동작을 이해하고 모델을 디버그하며 데이터 집합의 오류를 감지하는 데 도움이 됩니다.

다음 섹션에서는 영향력 기능의 이면에 있는 직관과 수학을 설명합니다.

**Math behind influence functions**

영향력 기능의 핵심 아이디어는 교육 인스턴스의 손실을 극히 작은 단계 $\epsilon$만큼 증가시켜 새로운 모델 매개 변수를 만드는 것입니다.

$$\hat{\theta}_{\epsilon,z}=\arg\min_{\theta{}\in\Theta}(1-\epsilon)\frac{1}{n}\sum_{i=1}^n{}L(z_i,\theta)+\epsilon{}L(z,\theta)$$

여기서 $\theta$는 모델 매개 변수 벡터이고 $\hat{\theta}_{\epsilon,z}$는 매우 작은 숫자 $\epsilon$로 z를 가중시킨 후 매개 변수 벡터입니다.
L은 모델을 교육한 손실 함수이며 $z_i$는 교육 데이터이며 z는 해당 모델 제거를 시뮬레이션하기 위해 상향 조정하려는 교육 인스턴스입니다.
이 공식 뒤에 숨겨진 직관은 다음과 같습니다.
교육 데이터에서 특정 인스턴스 $z_i$을(를) 약간 높이고 다른 데이터 인스턴스를 그에 따라 저울질하면 손실액은 얼마나 변경됩니까?
이 새로운 결합 손실을 최적화하기 위해 매개 변수 벡터는 어떻게 생겼습니까?
파라미터의 영향 기능, 즉 상향식 교육 인스턴스 z가 파라미터에 미치는 영향은 다음과 같이 계산할 수 있습니다.

$$I_{\text{up,params}}(z)=\left.\frac{d{}\hat{\theta}_{\epsilon,z}}{d\epsilon}\right|_{\epsilon=0}=-H_{\hat{\theta}}^{-1}\nabla_{\theta}L(z,\hat{\theta})$$

마지막 식 $\nabla_{\theta}L(z,\hat{\theta})$은(는) 가중 교육 인스턴스에 대한 매개 변수와 관련된 손실 구배입니다.
구배는 교육 인스턴스 손실률의 변화율입니다.
모델 매개변수 $\hat{\theta}$을(를) 약간 변경하면 손실이 얼마나 변하는지 알려줍니다.
구배 벡터의 양의 입력은 해당 모델 매개변수가 약간 증가하면 손실이 증가한다는 것을 의미하며, 음의 입력은 매개변수의 증가가 손실을 감소시킨다는 것을 의미합니다.
첫 번째 파트 $H^{-1}_{\hat{\theta}}$는 역 Hessian 매트릭스입니다(모델 파라미터와 관련된 손실의 두 번째 파생 모델).
헤시안 행렬은 경사의 변화율 또는 상실로 표현되는 손실률의 변화율입니다.
다음을 사용하여 추정할 수 있습니다.

$$H_{\theta}=\frac{1}{n}\sum_{i=1}^n\nabla^2_{\hat{\theta}}L(z_i,\hat{\theta})$$

보다 비공식적으로 다음을 수행합니다.
Hessian 매트릭스는 특정 지점에서 손실이 얼마나 곡선인지 기록합니다.
헤시안은 단순한 벡터가 아니라 매트릭스입니다. 왜냐하면 그것은 손실의 곡률과 곡률을 묘사하기 때문입니다. 우리가 보는 방향에 따라 말입니다.
파라미터가 많은 경우 Hessian 매트릭스의 실제 계산은 시간이 많이 소요됩니다.
고씨와 량씨는 효율적으로 계산하기 위해 몇 가지 묘책을 제안했는데, 이는 이 장의 범위를 벗어난 것입니다.
위의 공식에서 설명한 대로 모델 매개변수를 업데이트하는 것은 추정된 모델 매개변수 주위에 2차 확장이 형성된 후 하나의 뉴턴 단계를 수행하는 것과 같습니다.

이 영향 함수 공식 뒤에 어떤 직관이 있습니까?
이 공식은 $\hat{\theta}$ 매개 변수 주위에 2차 확장을 형성하는 데서 비롯됩니다.
즉, 인스턴스 z가 제거/업그레이드될 때 인스턴스 z의 손실이 정확히 어떻게 변화할지 계산하기가 너무 복잡합니다.
현재 모델 매개변수 설정에서 경사도(= 기울기) 및 곡률(= 헤시안 행렬)에 대한 정보를 사용하여 로컬에서 함수의 근사치를 계산합니다.
이 손실 근사치를 사용하여 인스턴스 z를 높인 경우 새 매개변수가 대략적으로 어떻게 표시되는지를 계산할 수 있습니다.

$$\hat{\theta}_{-z}\approx\hat{\theta}-\frac{1}{n}I_{\text{up,params}}(z)$$

대략적인 매개변수 벡터는 기본적으로 곡률에 의해 스케일링되고(= 역 헤시안 행렬로 곱하기) n에 의해 스케일링된 z 손실 경사를 뺀 원래 매개변수이다.

다음 그림은 상승 가중의 작동 방식을 보여 줍니다.
x축은 $\theta$ 매개 변수의 값을 나타내고 y축은 상승된 인스턴스 z로 손실된 값의 해당 값을 표시합니다.
여기의 모델 파라미터는 실증용으로는 1차원이지만, 실제로는 대개 고차원적입니다.
예를 들어 z와 같은 손실 개선 방향으로 1오버 n개만 이동합니다.
z를 삭제할 때 손실이 실제로 어떻게 변할지는 알 수 없지만, 손실 중 첫 번째와 두 번째 파생 모델에서는 현재 모델 매개변수 주위에 이차 근사치를 작성하고 실제 손실은 이렇게 동작한다고 가정합니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/quadratic-expansion-1.png'><br>
    <i>그림 6.19: 현재 모델 매개변수 주위에 손실량의 2차 확장을 형성하고 상승된 인스턴스 z(y-축)를 사용하여 손실이 가장 개선되는 방향으로 1/n을 이동하여 모델 매개변수(x-축)를 업데이트합니다. 손실 시 인스턴스 z의 이 상승 가중치는 감소된 데이터에 대해 z를 삭제하고 모델을 교육할 경우 파라미터 변경에 근사하게 됩니다.</i>
</p>

실제로 새 파라미터를 계산할 필요는 없지만 z가 파라미터에 미치는 영향의 척도로 영향 함수를 사용할 수 있습니다.

교육 인스턴스 z를 상향 조정할 때 *예측*은 어떻게 변화합니까?
새 파라미터를 계산한 다음 새로 매개변수화된 모델을 사용하여 예측하거나 체인 규칙을 사용하여 영향을 계산할 수 있으므로 인스턴스 z가 예측에 미치는 영향도 직접 계산할 수 있습니다.

$$\begin{align*}I_{up,loss}(z,z_{test})&=\left.\frac{d{}L(z_{test},\hat{\theta}_{\epsilon,z})}{d\epsilon}\right|_{\epsilon=0}\\&=\left.\nabla_{\theta}L(z_{test},\hat{\theta})^T\frac{d\hat{\theta}_{\epsilon,z}}{d\epsilon}\right|_{\epsilon=0}\\&=-\nabla_{\theta}L(z_{test},\hat{\theta})^T{}H^{-1}_{\theta}\nabla_{\theta}L(z,\hat{\theta})\end{align*}$$

이 방정식의 첫 번째 줄은 인스턴스 z의 가중치를 높이고 새 매개 변수 $\hat{\theta}_{\epsilon,z}$을(를) 가져올 때 특정 예측 $z_{test}$에 대한 교육 인스턴스의 영향을 테스트 인스턴스 손실 변화로 측정함을 의미합니다.
두 번째 라인의 경우, 파생 모델의 체인 규칙을 적용하고 파라미터에 대한 z의 영향을 곱한 파라미터와 관련하여 테스트 인스턴스(instance) 손실의 파생 모델을 얻습니다.
세 번째 줄에서는 표현식을 파라미터에 대한 영향 함수로 대체합니다.
세 번째 줄의 첫 번째 항은 $\nabla_{\theta}L(z_{test},\hat{\theta})입니다.^T{}$는 모델 매개변수에 대한 테스트 인스턴스의 구배입니다.

공식을 갖는 것은 위대하고 사물을 보여주는 과학적이고 정확한 방법입니다.
하지만 저는 이 공식의 의미를 직관적으로 이해하는 것이 매우 중요하다고 생각합니다.
$I_{\text{up, loss}$의 공식에 따르면, 인스턴스 $z_{test}$의 예측에 대한 교육 인스턴스 z의 영향 함수는 "모델 매개 변수의 변경에 대해 인스턴스가 강하게 반응하는 방식"에 "인스턴스 z의 가중치를 높일 때 매개 변수가 변경되는 양"을 곱한 것입니다.
공식을 읽는 또 다른 방법은 다음과 같습니다.
그 영향은 교육 및 테스트 손실에 대한 경사가 얼마나 큰지에 비례합니다.
교육 손실의 기울기가 높을수록 매개변수에 대한 영향과 시험 예측에 대한 영향도 높아집니다.
테스트 예측의 기울기가 높을수록 테스트 인스턴스에 영향을 줍니다.
전체 구성은 교육 과정과 테스트 인스턴스 간의 유사성(모델에서 학습한 대로)의 척도로도 볼 수 있습니다.

그것이 바로 이론과 직관입니다.
다음 섹션에서는 영향 기능을 적용하는 방법을 설명합니다.

**Application of Influence Functions**

영향 기능에는 많은 응용 프로그램이 있으며, 그 중 일부는 이미 이 장에 설명되어 있습니다.

**Understanding model behavior**

기계 학습 모델마다 예측 방법이 다릅니다.
두 모델의 성능이 동일하더라도, 두 모델의 기능 예측 방법은 매우 다를 수 있으므로 여러 시나리오에서 실패합니다.
영향력 있는 예를 식별하여 모델의 특정 약점을 이해하면 마음속에서 기계 학습 모델 동작의 "정신적 모델"을 형성하는 데 도움이 됩니다.
다음 그림은 지지 벡터 기계(SVM)와 신경 네트워크가 개와 물고기의 이미지를 구별하도록 훈련된 예를 보여줍니다.
모범적인 물고기 이미지의 가장 영향력 있는 예는 두 모델 모두 매우 달랐어요.
SVM의 경우 색상이 비슷한 경우 인스턴스가 영향을 받았습니다.
신경망의 경우, 개념적으로 유사할 경우 인스턴스가 영향을 받았습니다.
신경망의 경우, 가장 영향력 있는 이미지들 중 하나는 개의 이미지들 중 하나였고, 이것은 색 공간의 유클리드 거리가 아니라 개념을 배웠다는 것을 보여줍니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/influence-functions-svm-inception.jpg'><br>
    <i>그림 6.20: 개인가요, 생선인가요? 테스트 이미지와 유사한 색상을 가진 SVM 예측(중행) 영상의 영향이 가장 컸습니다. 신경망 예측(아래 행)의 경우, 다른 설정의 물고기가 가장 큰 영향을 미쳤지만, 도그 이미지(오른쪽 위)도 영향을 받았습니다. 고와 량(2017년)의 작품입니다.</i>
</p>


**Handling domain mismatches / Debugging model errors**

도메인 불일치를 처리하는 것은 모델 동작을 더 잘 이해하는 것과 밀접하게 관련되어 있습니다.
도메인 불일치는 교육 및 테스트 데이터의 분포가 다르다는 것을 의미하며, 이는 테스트 데이터에서 모델이 제대로 수행되지 않을 수 있습니다.
영향 기능은 오류를 일으킨 교육 인스턴스를 식별할 수 있습니다.
수술을 받은 환자의 결과에 대한 예측 모델을 교육했다고 가정합니다.
이 환자들은 모두 같은 병원 출신입니다.
이제 다른 병원에서 이 모델을 사용하게 되면 많은 환자들에게 효과가 없다는 사실을 알 수 있습니다.
물론, 두 병원이 다른 환자를 가지고 있다고 가정하고, 그들의 데이터를 보면, 많은 특징들이 다르다는 것을 알 수 있습니다.
하지만 모델을 "부러뜨린" 특징이나 인스턴스는 무엇일까요?
여기에서도, 영향력 있는 사례들이 이 질문에 대답하는 좋은 방법입니다.
모델이 잘못된 예측을 한 새 환자 중 하나를 선택하여 가장 영향력 있는 인스턴스를 찾아 분석합니다.
예를 들어, 이것은 두 번째 병원이 평균적으로 고령의 환자를 보유하고 있고 교육 데이터에서 가장 영향력 있는 사례는 첫 번째 병원의 몇 명의 노인 환자이며 이 부분군을 잘 예측하는 방법을 배울 데이터가 단순히 부족하다는 것을 보여줄 수 있다.
결론은 두 번째 병원에서 잘 일하기 위해서는 나이가 많은 더 많은 환자들을 대상으로 모델을 교육해야 한다는 것입니다.

**Fixing training data**

교육 인스턴스의 정확성을 확인할 수 있는 횟수에 제한이 있는 경우 어떻게 효율적으로 선택할 수 있습니까?
가장 좋은 방법은 가장 영향력 있는 예를 선택하는 것입니다. 왜냐하면, 정의상, 그것들은 모델에 가장 큰 영향을 미치기 때문입니다.
분명히 잘못된 값을 가진 인스턴스가 있는 경우에도 인스턴스가 영향을 받지 않고 예측 모델에 대한 데이터만 필요한 경우 영향력 있는 인스턴스를 확인하는 것이 좋습니다.
예를 들어 환자가 병원에 입원해야 하는지, 조기 퇴원해야 하는지 예측하기 위한 모델을 교육할 수 있습니다.
환자가 잘못 배출될 경우 좋지 않은 결과를 초래할 수 있으므로 모델이 견고하고 올바른 예측을 수행하는지 확인해야 합니다.
환자 기록은 매우 지저분할 수 있으므로 데이터의 품질에 대한 완벽한 신뢰도가 없습니다.
그러나 환자 정보를 확인하고 수정하는 것은 시간이 많이 소요될 수 있습니다. 왜냐하면 어떤 환자를 검사해야 하는지 보고한 후에는 병원이 실제로 사람을 보내서 선택된 환자의 기록을 좀 더 자세히 봐야 하기 때문입니다. 손으로 써서 일부 보관소에 누워 있을 수도 있습니다.
환자의 데이터를 확인하는 데 1시간 이상이 걸릴 수 있습니다.
비용 측면에서 중요한 데이터 인스턴스 몇 개만 확인하는 것이 좋습니다.
가장 좋은 방법은 예측 모델에 큰 영향을 미친 환자를 선택하는 것입니다.
고 씨와 량(2017년) 씨는 이런 유형의 선택이 무작위 선택이나 가장 손실이 크거나 분류가 잘못 된 사람들의 선택보다 훨씬 효과적이라는 것을 보여주었습니다.


### Advantages of Identifying Influential Instances

삭제 진단 및 영향 기능의 접근 방식은 [모델 인식](#anagnostic) 장에 제시된 대부분 기능별 교란 기반 접근 방식과는 매우 다릅니다.
영향력 있는 사례를 살펴보면 학습 프로세스에서 데이터 교육의 역할을 강조합니다.
따라서 영향 기능 및 삭제 진단 **기계 학습 모델을 위한 최고의 디버깅 도구 중 하나가 됩니다***.
이 책에서 제시된 기술 중 오류 여부를 확인해야 하는 인스턴스를 직접 식별하는 데 도움이 되는 기술은 이들 기술 뿐입니다.

**삭제 진단은 모델에 구애받지 않는**이므로 모든 모델에 적용할 수 있습니다.
또한 파생 모델에 기반한 영향 기능을 광범위한 모델에도 적용할 수 있습니다.

이러한 방법을 사용하여 **다른 기계 학습 모델을 비교하고**의 다양한 동작을 더 잘 이해할 수 있으며, 예측 성능만을 비교할 수 없습니다.

본 챕터에서는 이 주제에 대해 언급하지 않았지만, 파생 모델을 통한 **인플레이션 기능을 사용하여 적대적 교육 데이터**를 생성할 수도 있습니다.
이러한 인스턴스는 모형이 조작된 인스턴스에 대해 교육될 때 모형이 특정 테스트 인스턴스를 올바르게 예측할 수 없는 방식으로 조작된 인스턴스입니다.
[Adversrival 예제]장(#adversian)의 방법의 차이점은 공격이 훈련 시간 중에 발생한다는 것입니다(독살 공격이라고도 함).
관심이 있으시면 고 씨와 량 씨(2017년)의 논문을 읽어보세요.

삭제 진단 및 영향 기능의 경우 예측의 차이와 영향 기능의 경우 손실 증가를 고려하였습니다.
그러나 **이 접근 방식은 다음과 같은 양식에 대한 모든 질문에 대해 일반화할 수 있습니다**.
"어떻게 되지요... "인스턴스 z를 삭제하거나 업그레이드하는 경우"라고 말합니다. 여기서 원하는 모델의 기능을 모두 채울 수 있습니다."
교육 인스턴스가 모델의 전체 손실에 얼마나 영향을 미치는지 분석할 수 있습니다.
교육 인스턴스가 기능 중요도에 얼마나 영향을 미치는지 분석할 수 있습니다.
[decision tree](#tree)를 교육할 때 교육 인스턴스가 첫 번째 분할에 대해 선택한 기능에 얼마나 영향을 미치는지 분석할 수 있습니다.

### Disadvantages of Identifying Influential Instances

삭제 진단은 재교육이 필요하기 때문에**을 계산하는 데 매우 비용이 많이 듭니다.
하지만 역사는 컴퓨터 자원이 끊임없이 증가하고 있다는 것을 보여주었습니다.
20년 전에는 자원의 관점에서 생각할 수 없었던 계산은 스마트폰으로 쉽게 수행될 수 있습니다.
수천 개의 교육 인스턴스와 수백 개의 매개 변수를 가진 모델을 몇 초/분 만에 랩톱에서 교육할 수 있습니다.
따라서 10년 안에 대규모 신경망에서도 삭제 진단 기능이 문제없이 작동할 것이라고 가정하는 것은 큰 비약이라고 할 수 있습니다.

**유동 기능은 삭제 진단에 대한 좋은 대안이지만, 신경 네트워크와 같이 파라미터***가 다른 모델에 한해 사용할 수 있습니다.
그들은 무작위 숲, 강화된 나무 또는 결정 나무와 같은 나무 기반 방법에는 효과가 없습니다.
파라미터와 손실 기능이 있는 모델이 있더라도 손실은 다를 수 없습니다.
그러나 마지막 문제에 대해서는 다음과 같은 요령이 있습니다.
예를 들어 기본 모델이 힌지 손실을 일부 다른 손실 대신 사용하는 경우 영향을 계산하는 대신 다른 손실을 사용합니다.
손실은 영향 기능에 문제가 있는 손실의 매끄러운 버전으로 대체되지만 모델은 여전히 매끄러운 손실로 교육될 수 있습니다.

**유동 함수는 대략**에 불과합니다. 접근방식은 매개변수를 중심으로 2차 확장이 이루어지기 때문입니다.
근사치가 잘못될 수 있으며 제거 시 인스턴스의 영향이 실제로 더 크거나 더 낮습니다.
고 씨와 량(2017년) 씨는 일부 사례에서 영향함수에 의해 계산된 영향이 인스턴스(instance)가 삭제된 후 모델을 실제로 재교육했을 때 얻은 영향척도에 가깝다는 것을 보여주었습니다.
하지만 근사치가 항상 그렇게 가까울 것이라는 보장은 없습니다.

영향력 있는 인스턴스 또는 비인플레이션**이라고 하는 영향 측정치에 대한 명확한 구분은 없습니다.
영향을 받아 인스턴스를 분류하는 것은 유용하지만, 예를 분류할 뿐만 아니라 실제로 영향력 있는 것과 비인플레이션적인 것을 구별할 수 있는 수단을 갖추는 것이 좋을 것입니다.
예를 들어, 테스트 인스턴스에 가장 영향력 있는 상위 10개 교육 인스턴스를 식별하는 경우, 예를 들어 상위 3개 교육 인스턴스만 실제로 영향을 미치기 때문에 이들 중 일부는 영향을 받지 않을 수 있습니다.

영향 측정값 **개별 인스턴스**의 삭제만 고려하며 여러 인스턴스를 한 번에 삭제하는 것은 고려하지 않습니다.
데이터 인스턴스 그룹이 클수록 모델 교육 및 예측에 큰 영향을 미치는 몇 가지 상호 작용이 있을 수 있습니다.
하지만 문제는 조합에 있습니다.
데이터에서 개별 인스턴스를 삭제할 수 있습니다.
교육 데이터에서 두 인스턴스를 삭제할 수 있는 방법은 n번(n-1)입니다.
n번(n-1) 횟수(n-2)가 3회 삭제될 수 있습니다...
이게 어디로 가는지 알 수 있을 거예요. 조합이 너무 많거든요.

### Software and Alternatives

삭제 진단은 구현이 매우 간단합니다.
[코드](https://github.com/christophM/interpretable-ml-book/blob/master/manuscript/06.5-example-based-influence-fct)를 보세요.Rmd) 이 장의 예시를 위해 글을 썼습니다.

선형 모델과 일반화된 선형 모델의 경우, "통계" 패키지의 R에 쿡의 거리 같은 많은 영향 조치가 구현됩니다.

Koh와 Liang은 [리포지토리](https://github.com/kohpangwei/influence-release))에서 영향력 기능에 대한 Python 코드를 발표했습니다.
정말 멋지네요!
유감스럽게도 이 문서는 용지의 코드를 "만"하며 유지 관리되고 문서화된 Python 모듈이 아닙니다.
이 코드는 텐서플로우 라이브러리에 집중되어 있으므로 Sci-kit 학습과 같은 다른 프레임워크를 사용하는 블랙박스 모델에는 직접 사용할 수 없습니다.

Keita Kuita는 [영향력 기능을 위한 위대한 블로그 게시물](##more-641)을 써서 고 씨와 량 씨의 논문을 더 잘 이해할 수 있게 해 주었습니다.
이 블로그 포스트는 블랙박스 모델의 영향 기능 뒤에 있는 수학에 좀 더 깊이 들어가며, 또한 이 방법이 효율적으로 구현되는 일부 수학적인 '트릭스'에 대해서도 이야기합니다.

---

[^1]: Cook, R. Dennis. "Detection of influential observation in linear regression." Technometrics 19.1 (1977): 15-18.

[^2]: Koh, Pang Wei, and Percy Liang. "Understanding black-box predictions via influence functions." arXiv preprint arXiv:1703.04730 (2017).