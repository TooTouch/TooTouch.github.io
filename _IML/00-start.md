---
title:  "역자의 말"
permalink: /IML/start/
---

# Interpretable Machine Learning

## 해석가능한 머신 러닝

<p align="center">
    <img src='https://drive.google.com/uc?id=18ff1TLXk9bxrKAB9Q_Yrze9xbMru3vOQ' width='500'/><br>
    <i>Interpretable Machine Learning E-book</i>
</p>

최근 머신러닝에 대한 관심이 높아지고 기술이 점점 발전함에 따라 그동안 사람이 반복적으로 하던 일들은 하나씩 자동화되어 대체되었고 해결하지 못했던 일들은 머신러닝이 해결해주고 있습니다. 시간이 지나면서 데이터는 점점 더 쌓여가고 방대한 데이터를 학습하기위해 모델 또한 크고 복잡해지고 있습니다. 흔히 말하는 머신러닝의 **'블랙 박스(Black Box)'**가 복잡한 모델의 결과를 해석하지 못하는 경우를 말합니다.

<p align="center">
    <img src='https://drive.google.com/uc?id=1VBxv6TUAEw_l73SEbsim71LxFo3n0PoF' width='800'/>
</p>

머신러닝의 상용화와 더불어 크게 문제가 되고있는 부분은 바로 **'인공지능의 차별'**입니다. 2016년 처음 마이크로소프트에서 서비스했던 인공지능 챗봇 '테이(Tay)'는 시작한지 몇시간도 안돼서 잘못된 데이터를 통해 심한 욕설과 인종·성차별을 하기 시작했고 16시간만에 서비스를 중단하고 말았습니다. 2018년에는 MIT에서 'Norman'이라는 싸이코패스 인공지능을 의도적으로 만들기도 했고 아마존에서는 채용시스템에 머신러닝 모델을 적용했다가 성차별 논란을 일으키기도 하였습니다. 이러한 문제를 해결하기 위해서는 모델이 왜 이러한 결정을 내렸는지 확인할 수 있어야합니다. 블랙 박스 문제를 해결할 수 있다면 인공지능의 차별적인 부분 또한 해결할 수 있습니다.

<p align="center">
    <img src='https://drive.google.com/uc?id=1qqUIwsG5ZP8dOFXTNvLQ87LcDVswXbua' width='800'/>
</p>

데이터 사이언티스트가 되기위해 어떤 역량을 갖추는게 맞을까라는 고민을 하다가 바로 이러한 모델의 복잡성을 해결하여 설명력을 갖추는것이 데이터 사이언티스트가 가져야할 역량 중 하나가 아닐까라는 생각을 하게 되었습니다. 때문에 이전부터 계속해서 화두가 되고있는 Explainable A.I. 분야를 공부하며 정형데이터부터 Computer Vision과 NLP까지 다양한 분야의 해석방법에 대해서 찾아보고 있습니다. 그러던 중 우연히 이 책을 알게되었고, 공부도 하고 많은 사람들과 공유하고자 저자의 허락을 맡고 번역글을 작성하게 되었습니다. 좋은 책을 작성해준 Christoph Molnar에게 감사의 말을 전하며 이제 열심히 번역해 보겠습니다!

번역글을 많이 작성해본 경험이 없기 때문에 다소 번역한 문장이나 단어가 어색할 수 있습니다. 그러나 최대한 원문의 내용을 반영하여 왜곡되지 않도록 번역을 하고있고 한국어로 표현하기에 적절하지 않은 문장이나 단어는 원문을 그대로 인용하였습니다. 

> *혹시나 잘못된 내용이 있다면 아래 메일을 통해 문의해주시면 감사드리겠습니다.*  
[*wogur379@gmail.com*](mailto:wogur379@gmail.com)

---

1. Molnar, Christoph. "Interpretable machine learning. A Guide for Making Black Box Models Explainable", 2019. https://christophm.github.io/interpretable-ml-book/.