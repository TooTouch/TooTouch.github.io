---
title:  "2.3 Scope of Interpretability"
permalink: /IML/scope_of_interpretability/
---

5:00 pm

알고리즘은 모델이 예측값을 만들어낼 수 있도록 학습시킵니다. 각 단계는 투명하게 또는 해석가능하게 평가되어야 합니다.

# 1. 알고리즘의 투명성
**Algorithm Transparency**

*알고리즘은 어떻게 모델을 만드는가?*

알고리즘의 투명성은 알고리즘이 어떻게 데이터를 통해서 모델을 학습시키는지와 어떤 관계로 학습시킬 것인지를 말합니다. 이미지를 분류하기위해 합성곱 신경망을 사용하는 경우에는 첫 레이어에서는 테두리를 찾도록 학습시킨다고 설명할 수 있습니다. 그러나 이건 알고리즘이 어떻게 작동되는지 이해하는 것이지 특정 모델이 마지막까지 어떻게 학습되는지나 각 결과값이 어떻게 만들어지는 지에 대한것이 아닙니다. 알고리즘 투명성은 데이터나 학습된 모델에서가 아닌 단지 알고리즘에 대한 이해가 필요할 뿐입니다. 이 책은 모델의 해석가능성에 대한 책이고 알고리즘의 투명성에 대한 책이 아닙니다. 선형 모델에 대한 최소제곱법과 같은 알고리즘은 이미 많이 연구되어졌고 쉽게 이해할 수 있습니다. 이 방법은 이미 공식적으로도 증명되었습니다. 딥러닝 방법(수백만게의 가중치를 네트워크를 통해 기울기를 조정하는)은 아직 더 많은 이해가 필요하고 내부적인 내용들은 아직 연구 중입니다. 이들은 아직 덜 투명하다고 할 수 있습니다. 

# 2. 전체론적 모델 해석가능성
**Global, Holistic Model Interpretability**

*학습된 모델을 어떻게 예측값을 만드는가?*

모델 전체를 한눈에 이해할 수 있다면 모델을 설명할 수 있을 것입니다 (Lipton 2016[^1]). 전제적으로 모델 결과를 설명하기위해서는 학습된 모델, 알고리즘에 대한 이해 그리고 데이터가 필요합니다. 해석가능성의 수준은 가중치나 다른 파라미터 그리고 모델 구조와 같은 학습시킨 구성요소들과 각 특성들에 대한 전체적인 관점을 기반으로 모델이 어떻게 의사결정을 내렸는지 이해하는 것을 나타냅니다. 어떤 특성이 중요한지와 특성간 무슨 상호작용이 발생했는가? 에 대해 전체론적 모델 해석가능성은 각 특성에 대한 목표값의 분포를 이해할 수 있게 해준다. 전체론적 모델 해석가능성은 일반적으로 다루기가 아주 어렵습니다. 파라미터나 가중치가 일정 수 이상 넘어가면 사람의 수준으로 다루기 어려워질 수 있습니다. 여러분이 5개의 특성을 가진 선형 모델을 머리 속에 상상하는것은 불가능 합니다. 이 말은 5차원 공간에 초평면(hyperplane)을 그린다는 것과 같은 뜻이기 때문입니다. 3차원 이상의 특성 공간은 인간의 상상 범위 밖입니다. 그래서 보통은 모델을 이해하기 위해서 선형모델의 가중치와 같은 모델의 일부분에 대해서만 고려합니다. 

# 3. 모듈 수준에서 전체론적 모델 해석가능성
**Global Model Interpretability on a Modular Level**

*모델의 각 부분들은 예측값에 얼마나 영향을 미칠까?*

수백개의 특성이 있는 나이브 베이즈 모델 저와 여러분이 기억하기에는 너무 많을 수 있습니다. 모든 가중치를 기억한다 하더라도 새로운 데이터에 대해 빠르게 예측값을 낼 수 없습니다. 게다가 각 특성들의 중요도를 평가하고 각 특성이 얼마나 예측값에 평균적으로 영향을 미쳤는지 계산하기위해 여러분 머리 속에는 모든 특성들의 결합 분포를 가지고 있어야합니다. 이건 불가능합니다. 그러나 단일 가중치에 대해서는 쉽게 이해할 수 있습니다. 전체론적 모델 해석가능성은 보통은 능력밖의 일이지만 몇몇 모델에 대해서는 모듈 수준으로 이해할 수 있습니다. 모든 모델은 파마미터 수준에서 해석할 수 있는건 아닙니다. 선형 모델에서는 해석가능한 부분이 가중치에 있고 트리 모델에서는 분할(특성들을 선택하고 일정 지점으로 나누는)과 나뭇잎 노드의 예측값에 있습니다. 예들 들어 선형 모델은 모듈 수준에서 완벽하게 해석할 수 있는 것처럼 보이지만 단일 가중치의 해석은 다른 모든 가중치와 연관되어 있습니다. 단일 가중치에 대한 해석은 다른 특성들이 같은 값을 가지고 있다는 가정하에 이루어지는데 실제로 그런 경우는 없습니다. 집 크기와 방 수를 고려해서 집 값을 예측하는 선형 모델은 방을 나타내는 특성에 대해 음수값을 갖는 가중치를 가질 수 있습니다. 이는 이미 집 크기에 대한 특성과 큰 상관관계를 가지고 있기 때문입니다. 더 큰 방을 선호하는 사람들이 있는 곳에서는 두 집이 같다는 가정하에 많은 방보다 적은 방의 집이 더 좋을 수 있습니다. 가중치는 모델의 다른 특성들에 대한 맥락을 고려해야합니다. 그래도 선형 모델의 가중치는 깊은 신경망 모델의 가중치보다 더 해석하기 쉽습니다.

# 4. 단일 예측치에 대한 지역적 해석가능성
**Local Interpretability for a Single Prediction**

*왜 모델은 하나의 관측치에 대해 특정 예측값을 만드는 것일까?*

여려분은 단일 관측치에 대해 생각해보고 과연 이 입력값에 대해 모델은 무엇을 예측할지 조사하고 이유를 설명할 수 있습니다. 개별적으로 예측값을 본다고 한다면 원래는 복잡했던 모델을 복잡하지 않게, 감사하게 볼 수 있습니다. 지역적으로 예측값은 몇몇 특성들에 대해 복잡한 관계를 갖는 것이 아닌 선형적으로나 단조로운 관계를 갖고 있습니다. 예를 들어 집 값은 크기와 비선형적인 관계를 가집니다. 그러나 단지 특정 100 제곱미터의 집에 대해서만 본다면 이 값이 데이터에 속해있는 경우 모델의 예측값은 크기에 대해 선형적인 관계로 볼 수 있습니다. 그렇다면 이제 집 크기가 10 제곱미터씩 커지거나 작아질수록 예측한 집 값이 어떻게 변화하는지 시연해볼 수 있습니다. 지역적 설명은 즉 전체적 설명보다 더 정확하게 나타낼 수 있습니다. 이 책은 model-agnostic 방법에 대한 섹션에서 개별적인 예측값에 대한 더 많은 해석방법을 소개합니다.

# 5. 집단 예측치에 대한 지역적 해석가능성
**Local Interpretability for a Group of Predictions**

*왜 모델은 집단의 관측치에 대해 특정 예측값을 만드는 것일까?*

다중 관측치에 대한 모델 예측값은 전체 모델에 대한 해석방법(모듈 수준)과 단일 관측치에 대한 설명 둘 다 사용하여 설명될 수 있습니다. 전체적인 방법은 집단을 전체 데이터로 취급하여 집단의 관측치에 전체 해석 방법을 적용할 수 있습니다. 개별 해석 방법은 각 관측치에 대해 사용할 수 있고 그 후 전체 집단에 대해 나열하거나 결합하여 나타낼 수 있습니다.

---

[^1]: Lipton, Zachary C. “The mythos of model interpretability.” arXiv preprint arXiv:1606.03490, (2016).