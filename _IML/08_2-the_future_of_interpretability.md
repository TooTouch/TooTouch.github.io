---
title:  "8.2 The Future of Interpretability"
permalink: /IML/the_future_of_interpretability/
---

# The Future of Interpretability

기계 학습의 가능한 미래에 대해 살펴보겠습니다.


**모델에 구애받지 않는 해석 도구에 초점을 맞출 것입니다.**

기본 기계 학습 모델에서 분리되면 해석성을 자동화하는 것이 훨씬 더 쉽습니다.
모델에 구애받지 않는 해석성의 장점은 모듈화에 있습니다.
우리는 기초적인 기계 학습 모델을 쉽게 대체할 수 있습니다.
우리는 해석 방법을 쉽게 대체할 수 있습니다.
이러한 이유로, 모델에 구애받지 않는 방법이 훨씬 더 잘 확장될 것입니다.
이것이 제가 모델과 무관한 방법들이 장기적으로 더 우세해질 것이라고 믿는 이유입니다.
하지만 본질적으로 해석할 수 있는 방법에도 장소가 있을 것입니다.


**기계 학습은 자동화되고 해석성이 향상됩니다.**

이미 가시화된 추세는 모델 교육의 자동화이다.
여기에는 자동화된 엔지니어링 및 기능 선택, 자동화된 하이퍼 파라미터 최적화, 서로 다른 모델의 비교, 모델의 통합 또는 스택이 포함됩니다.
결과는 가장 좋은 예측 모델입니다.
모델에 구애받지 않는 해석 방법을 사용하면 자동화된 기계 학습 프로세스에서 나타나는 모든 모델에 자동으로 적용할 수 있습니다.
어떻게 보면 이 두 번째 단계도 자동화할 수 있습니다.
피쳐 중요도를 자동으로 계산하고 부분 의존도를 표시하고 대리모형을 교육합니다.
아무도 이 모든 모델 해석을 자동으로 계산하는 것을 막지 못합니다.
실제 해석은 여전히 사람을 필요로 합니다.
상상해 보세요: 데이터 세트를 업로드하고 예측 목표를 지정하고 버튼을 누르면 최상의 예측 모델이 교육되며 프로그램에서 모델에 대한 모든 해석을 생략합니다.
이미 첫 번째 제품이 있고, 저는 많은 어플리케이션의 경우 이러한 자동화된 기계 학습 서비스를 사용하기에 충분하다고 주장합니다.
오늘날 누구나 HTML, CSS, Javascript를 알지 않고도 웹사이트를 만들 수 있지만, 여전히 주변에 많은 웹 개발자들이 있습니다.
비슷하게, 저는 모든 사람들이 어떻게 프로그램을 짜는지 모르게 기계 학습 모델을 훈련시킬 수 있을 것이고, 여전히 기계 학습 전문가들에 대한 요구가 있을 것이라고 믿습니다.


**데이터를 분석하지 않고 모델을 분석합니다.**

원시 데이터 자체는 항상 무용지물입니다.
(저는 일부러 과장합니다.
의미 있는 분석을 하려면 데이터에 대한 깊은 이해가 필요한 것이 현실입니다.)
저는 그 데이터에 대해 신경쓰지 않습니다.
저는 데이터에 포함된 지식에 신경을 씁니다.
해석 가능한 기계 학습은 데이터에서 지식을 얻는 좋은 방법입니다.
모형을 광범위하게 탐색할 수 있고, 모형은 피쳐가 예측과 관련이 있는지와 어떻게 관련이 있는지를 자동으로 인식합니다(많은 모형은 내장 피쳐 선택을 가지고 있음). 모형은 관계가 어떻게 표현되는지를 자동으로 감지할 수 있으며, 올바르게 훈련된 경우 최종 모형은 매우 훌륭한 현실 근사치입니다.


많은 분석 도구는 이미 데이터 모델을 기반으로 합니다(배분 가정에 기반하기 때문에).

- 학생의 t-검정처럼 단순한 가설 검정입니다.
- 교란기(일반적으로 GLM)를 조정하여 가설 검정합니다.
- 분산 분석(분산)입니다.
- 상관 계수(표준화된 선형 회귀 계수는 Pearson의 상관 계수와 관련이 있습니다)
- ...

제가 여기서 말하는 것은 사실 새로운 것이 아닙니다.
그렇다면 왜 가정 기반 투명 모델 분석에서 가정 없는 블랙박스 모델 분석으로 전환했을까요?
이러한 모든 가정을 하는 것은 문제가 되기 때문입니다.
일반적으로 잘못된 것입니다(전 세계 대부분이 가우스 분포를 따른다고 생각하지 않는 한). 확인하기가 어렵고, 매우 유연하지 않으며 자동화하기 어렵습니다.
대부분의 도메인에서 가정 기반 모델은 일반적으로 블랙박스 기계 학습 모델보다 손대지 않은 테스트 데이터의 예측 성능이 더 낮습니다.
이는 빅 데이터 세트에만 해당되며, 우수한 가정을 가진 해석 가능한 모델은 블랙박스 모델보다 작은 데이터 세트로 성능이 더 뛰어난 경우가 많기 때문입니다.
블랙박스 기계 학습 방식은 많은 데이터가 있어야 제대로 작동합니다.
모든 것이 디지털화됨에 따라 우리는 더 큰 데이터셋을 갖게 될 것이며, 따라서 기계 학습의 접근 방식이 더욱 매력적으로 될 것입니다.
우리는 추정을 하지 않고 가능한 한 현실에 가깝게 접근합니다(교육 데이터의 오버핏은 피하면서).
저는 우리가 질문에 답하기 위해 통계에서 가지고 있는 모든 도구(가정 테스트, 상관 관계 측정, 상호작용 측정, 시각화 도구, 신뢰 구간, p-값, 예측 간격, 확률 분포)를 개발하고 블랙박스 모델에 맞게 다시 작성해야 한다고 주장합니다.
어떻게 보면 이미 다음과 같은 상황이 벌어지고 있습니다.

- 고전적인 선형 모델을 살펴보겠습니다. 표준화된 회귀 계수는 이미 피쳐 중요도 측정값입니다.
[허용특성 중요도 측정](#feature-importance)을 통해 어떤 모델과도 호환되는 도구를 보유하고 있습니다.
- 선형 모형에서 계수는 예측된 결과에 대한 단일 형상의 영향을 측정합니다.
이것의 일반화된 버전은 [부분 의존도 그림](#pdp)입니다.
- A인지 B인지 테스트합니다.