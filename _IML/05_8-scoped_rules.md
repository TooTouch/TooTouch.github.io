---
title:  "5.8 Scoped Rules (Anchors)"
permalink: /IML/scoped_rules/
toc: true
---

# Scoped Rules (Anchors)

*Authors: Tobias Goerke & Magdalena Lang*

Anchors는 예측을 충분히 "포착(Anchors)"하는 의사결정 규칙을 찾아 블랙박스 분류 모델의 개별 예측을 설명합니다.
규칙은 다른 특성 값의 변경이 예측에 영향을 미치지 않는 경우 예측을 anchor합니다.
Anchors는 강화 학습 기법을 그래프 검색 알고리즘과 함께 사용하여 모델 호출 수(필요한 실행시간)를 최소화하는 동시에 로컬 옵티마를 피할 수 있습니다. Ribeiro, Singh, 그리고 Guestrin은 [LIME](https://tootouch.github.io/IML/local_surrogate/) 알고리즘을 제안한 연구원들이고 2018년에 이 알고리즘[^1]을 제안했습니다.

이전 과정과 마찬가지로 앵커 접근 방식도 *perturbation 기반* 전략을 구현하여 블랙박스 머신러닝 모델의 예측에 대한 *로컬* 설명을 생성합니다. 그러나 LIME에서 사용하는 대체 모델 대신 결과 설명을 *앵커*라고 하는 이해하기 쉬운 *IF-THEN* 규칙으로 표현합니다. 이러한 규칙은 *범위*이기 때문에 재사용할 수 있습니다. 앵커에는 적용 범위를 정확하게 나타내는 적용 범위 개념이 포함되어 있습니다. 앵커를 찾는 것은 강화 학습의 훈련에서 비롯되는 exploration이나 multi-armed bandit 문제를 포함합니다. 이를 위해 설명되고 있는 모든 관측치에 대해 이웃, 즉 변화가 생성되고 평가됩니다. 이렇게 하면 블랙박스의 구조와 내부 매개변수를 무시하여 블랙박스가 관찰되지 않거나 변경되지 않은 상태로 유지되도록 할 수 있습니다. 따라서 이 알고리즘은 *model-agnostic*으로, **어떤** 모델에도 적용할 수 있습니다.

저자들은 논문에서 두 가지 알고리즘을 모두 비교하고 결과를 도출하기 위해 한 관측치의 이웃을 얼마나 다르게 참조하는지 시각화합니다. 이를 위해 다음 그림은 LIME과 앵커를 모두 로컬로 설명하는 그림입니다(예: **-** 또는 **+**를 예측). LIME의 결과는 LIME이 perturbation 공간 $$D$$에 주어진 모델에 가장 근접한 선형 의사결정 경계를 학습하기 때문에 얼마나 충실한지를 나타내지 않습니다. 동일한 perturbation 공간을 고려하는 앵커 접근방식은 모델의 행동에 적용 범위가 조정된 설명을 구성하고 경계를 명확하게 표현합니다. 따라서 어떤 경우에 적합한지 설계 및 상태에 따라 충실합니다. 이 특성은 앵커를 특히 직관적이고 이해하기 쉽게 만듭니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/anchors-visualization.png'><br>
    <i>그림 5.37: LIME vs. 앵커 - 간단한 시각화입니다. Ribeiro, Singh, 그리고 Guestrin(2018년)의 그림입니다.</i>
</p>

앞에서 언급한 바와 같이 알고리즘의 결과나 설명은 앵커라고 하는 규칙의 형태로 나옵니다. 다음 간단한 예제에서는 이러한 앵커에 대해 설명합니다. 예를 들어, 우리에게 승객들이 타이타닉 재난에서 살아남을지 여부를 예측하는 이항 블랙박스 모델이 주어진다고 가정해보세요. 이제 모델이 생존할 수 있는 특정 개인에 대해 *why*를 예측하고 싶습니다. 앵커 알고리즘은 아래에 표시된 것과 같은 결과의 설명을 제공합니다.


한 명의 예시과 모델의 예측입니다.

| Feature         | Value         |
| --------------- |:-------------:|
| Age             | 20            |
| Sex             | female        |
| Class           | first         |
| TicketPrice     | 300\$          |
| More attributes | ...           |
| **Survived**    | **true**      |


앵커의 설명은 다음과 같습니다.

IF `SEX = female`  
AND `Class = first`  
THEN PREDICT `Survived = true`  
WITH PRECISION `97%`  
AND COVERAGE `15%`  
 
이 예제는 앵커가 모델의 예측과 그 근본적인 추론에 대한 필수적인 통찰력을 제공하는 방법을 보여줍니다. 그 결과, 어떤 속성이 모델에 의해 고려되었는가를 알 수 있는데, 이 경우, 여성과 일등석입니다. 우리는 정확성을 위해 가장 중요한 역할을 하는 이 규칙을 사용하여 모델의 동작을 검증할 수 있습니다. 앵커는 perturbation 공간 관측치의 15%에 해당한다고 추가로 알려줍니다. 이 경우 설명은 97%의 정확성을 나타냅니다. 이는 표시된 예측조건들이 예측된 결과에 거의 전적으로 책임이 있음을 의미합니다.

앵커 $$A$$는 공식적으로 다음과 같이 정의됩니다.

$$\mathbb{E}_{\mathcal{D}_x(z|A)}[1_{f(x)=f(z)}]\geq\tau,A(x)=1$$

여기서 다음과 같은 작업을 수행할 수 있습니다.

- $$x$$는 설명되는 관측치(예: 표 데이터 세트의 한 행)를 나타냅니다.
- $$A$$는 $$A$$로 정의된 모든 특성 예측조건이 $$x$$의 특성 값에 해당하는 경우 $$A(x)=1$$와 같은 결과 규칙 또는 앵커의 예측조건 집합입니다.
- $$f$$는 설명할 분류 모델(예: 인공 신경망 모델)을 나타냅니다. $$x$$ 및 해당 perturbation에 대한 레이블을 예측하도록 대입할 수 있습니다.
- $$D_x (\cdot\|A)$$는 $$A$$와 일치하는 $$x$$의 이웃 분포를 나타냅니다.  
- $$0 \leq \tau \leq 1$$는 정확성에 대한 임계값을 지정합니다. 최소 $$\tau$$의 로컬 충실도를 달성하는 규칙만 유효한 결과로 간주됩니다.

공식 설명은 위협적일 수 있으며 다음과 같이 표현할 수 있습니다.

> 설명할 관측치 $$x$$을(를) 고려할 때 $$A$$에 적용되는 규칙 또는 앵커 $$A$$을(를) 찾아야 하며, $$A$$가 적용되는 $$x$$의 이웃 중 적어도 $$\tau$$에 대해 $$x$$에 해당하는 클래스가 예측됩니다. 규칙의 정밀도는 제공된 머신러닝 모델(표시 함수 $$1_{f(x) = f(z)}$$로 표시됨)을 사용하여 이웃 또는 $$D_x(z\|A)$$을 따르는 perturbation를 평가하여 얻습니다.

# Anchors 찾기

비록 앵커들의 수학적인 설명이 명확하고 간단해 보일지라도, 특정한 규칙을 구성하는 것은 불가능합니다. 모든 $$z\in \mathcal{D}_x(\cdot\|A)$$에 대해 $$1_{f(x) = f(z)}$$를 평가해야 합니다(이는 연속 또는 큰 입력 공간에서 불가능 합니다). 따라서 저자들은 확률론적 정의를 생성하기 위해 $$0 \leq \delta \leq 1$$ 파라미터를 도입할 것을 제안합니다. 이렇게 하여 정밀도에 대한 통계적 신뢰도가 있을 때까지 샘플을 채취합니다. 확률론적 정의는 다음과 같습니다.

$$P(prec(A)\geq\tau)\geq{}1-\delta\quad\textrm{with}\quad{}prec(A)=\mathbb{E}_{\mathcal{D}_x(z|A)}[1_{f(x)=f(z)}]$$

이전의 두 정의는 적용 범위 개념에 의해 결합되고 확장됩니다. 그 근거는 모델의 입력 공간에서 가급적 큰 부분에 적용되는 규칙을 찾는 것으로 구성됩니다. 범위는 공식적으로 앵커들이 이웃에 적용할 확률(즉, perturbation 공간)로 정의됩니다.

$$cov(A)=\mathbb{E}_{\mathcal{D}_{(z)}[A(z)]}$$ 

이 요소를 포함하면 범위의 극대화를 고려한 앵커의 최종 정의가 도출됩니다.

$$\underset{A\:\textrm{s.t.}\;P(prec(A)\geq\tau)\geq{}1-\delta}{\textrm{max}}cov(A)$$

따라서 이 절차는 모든 적용 대상 규칙(확률론적 정의에 따라 정밀도 임계값을 충족하는 모든 규칙) 중에서 적용 범위가 가장 높은 규칙을 찾습니다. 이러한 규칙은 모델의 더 큰 부분을 설명하기 때문에 더 중요한 것으로 여겨집니다.
예측조건이 많은 규칙은 예측조건가 적은 규칙보다 정밀도가 높은 경향이 있습니다. 특히 $$x$$의 모든 특성을 고정하는 규칙은 평가한 인접 영역을 동일한 관측치로 축소합니다. 따라서 모델은 모든 이웃을 같은 클래스로 분류하며 규칙의 정확도는 1입니다. 동시에 많은 특성을 고정하는 규칙은 지나치게 구체적이며 일부 관측치에만 적용됩니다. 따라서 *정밀도와 범위는 절충의 관계*를 가집니다.

앵커 접근 방식은 아래 그림과 같이 네 가지 주요 구성 요소를 사용하여 설명을 찾습니다.

**후보 생성**: 새 설명 후보를 생성합니다. 첫 번째 라운드에서는 $$x$$의 특성당 후보 1개가 생성되어 가능한 perturbation의 각 값을 수정합니다. 나머지 라운드에서는, 이전 라운드에서 가장 우수한 후보가 아직 포함되지 않은 하나의 특성의 예측조건으로 확장해 나아갑니다.

**최우수 후보 식별**: 후보 규칙은 $$x$$를 가장 잘 설명하는 규칙과 관련하여 비교해야 합니다. 이를 위해 현재 관찰된 규칙과 일치하는 perturbation을 모델에 호출하여 평가합니다. 그러나 이러한 호출은 과도한 연산을 제한하기 위해 최소화되어야 합니다. 이것이 바로 이 요소의 핵심에 pure-exploration Multi-Armed-Bandit(*MAB*; *KL-LUCB*[^2])가 있는 이유입니다. MAB는 순차적 선택을 사용하여 서로 다른 전략(슬롯 머신에 비유하여 암이라고 함)을 효율적으로 탐색하고 활용하는 데 사용됩니다. 주어진 설정에서 각 후보 규칙은 당길 수 있는 팔로 간주됩니다. 당길 때마다 각 이웃에 대한 평가가 이루어지며, 이에 따라 후보 규칙의 보수에 대한 자세한 정보(앵커 사례의 정확성)를 얻을 수 있습니다. 따라서 정밀도는 규칙이 설명할 관측치를 얼마나 잘 설명하는지를 나타냅니다.

**정밀도 검증**: 후보가 $\tau$ 임계값을 초과했다는 통계적 신뢰도가 아직 없는 경우 더 많은 샘플을 채취합니다.

**Beam Search 변형**: 위의 모든 구성 요소는 그래프 검색 알고리즘이자 breadth-first 알고리즘의 변형인 Beam Search로 구성됩니다. 각 라운드의 최우수 $$B$$ 후보들을 다음 라운드에 전달합니다($$B$$를 *Beam Width*이라고 함). 그러면 이러한 $$B$$ 최상의 규칙이 새 규칙을 만드는 데 사용됩니다. Beam Search는 최대 $$featureCount(x)$$ 라운드에서 수행됩니다. 각 특성은 한 번에 규칙에 포함될 수 있기 때문입니다. 따라서 각 라운드 $$i$$마다 정확히 $$i$$의 기호를 가진 후보를 생성하고 그 중에서 최선의 $$B$$를 선택합니다. 따라서 $$B$$를 크게 설정하면 알고리즘이 로컬 옵티마를 피할 가능성이 높아집니다. 그러나 많은 수의 모델 호출이 필요하므로 계산 부하가 증가합니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/anchors-process.jpg'><br>
    <i>그림 5.38: 앵커 알고리즘의 구성 요소 및 상호 관계(단순화됨)</i>
</p>

이 접근법은 왜 어떤 시스템이 어떤 예를 그렇게 분류했는지에 대한 통계적으로 적절한 정보를 효율적으로 도출하기 위한 완벽한 방법입니다. 모델의 입력을 체계적으로 실험하고 각 출력을 관찰하여 결론을 내립니다. 머신러닝 방법(MABs)를 활용하여 모델에 대한 호출 횟수를 줄입니다. 이렇게 하면 알고리즘의 실행시간이 크게 줄어듭니다.

# 복잡도 및 실행시간

앵커 접근 방법이 동작하는 실행시간을 알면 특정 문제에 대해 얼마나 잘 수행될 것으로 예상되는지를 평가하는 데 도움이 됩니다. $$B$$는 빔 너비를 나타내고 $$p$$는 모든 특성의 수를 나타냅니다. 그런 다음 앵커 알고리즘은 다음과 같은 영향을 받습니다.

$$\mathcal{O}(B\cdot{}p^2+p^2\cdot\mathcal{O}_{\textrm{MAB}\lbrack{}B\cdot{}p,B\rbrack})$$

이 경계는 통계적 신뢰도 $$\delta$$와 같은 문제와는 별개인 하이퍼 파라미터로에 달려있습니다. 하이퍼 파라미터를 무시하면 경계의 복잡성을 줄일 수 있습니다(자세한 내용은 원본 용지 참조). MAB는 각 라운드에서 $$B \cdot p$$ 후보 중 최선의 $$B$$를 추출하므로 대부분의 MAB와 그 실행시간은 다른 파라미터보다 $$p^2$$배 오래걸립니다.

따라서 특성이 많을 수록 이 알고리즘은 비효율적입니다.

# 표 데이터 예시

표 데이터는 표로 표시된 구조화된 데이터로, 열에는 특성 및 행에는 관측치가 포함되어 있습니다.
예를 들어, [자전거 대여 데이터](https://tootouch.github.io/IML/bike_rentals/)를 사용하여 선택한 관측치에 대한 ML 예측을 설명하는 앵커 접근 방식을 시각화합니다. 이를 위해 회귀 분석을 분류 문제로 전환하고 블랙박스 모델로 랜덤 포레스트를 학습합니다. 대여된 자전거의 수가 트렌드 기준보다 위인지 아래인지 구분하였습니다.

앵커 설명을 만들기 전에 perturbation 함수을 정의해야 합니다. 이를 위한 쉬운 방법은 표 설명 사례에 직관적인 기본 perturbation 공간을 사용하는 것입니다. 표 설명 사례에서는 학습 데이터를 샘플링하여 만들 수 있습니다.
관측치를 perturbation시킬 때 이 기본 접근방식은 고정되지 않은 특성을 지정된 확률로 임의 추출한 다른 관측치에서 가져온 값으로 대체하면서 앵커의 예측조건에 해당하는 특성의 값을 유지합니다. 이 프로세스는 설명된 관측치와 유사하지만 다른 임의 관측치에서 일부 값을 채택한 새 관측치를 생성합니다. 그래서 이 값들은 이웃과 비슷한 값을 가집니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/unnamed-chunk-25-1.png'><br>
    <i>그림 5.39: 자전거 대여 데이터 세트의 6가지 관측치를 설명하는 앵커입니다. 각 행은 하나의 설명 또는 앵커를 나타내며, 각 막대는 이 행에 포함된 특성 예측조건을 나타냅니다. x축에는 규칙의 정밀도가 표시되며 막대의 두께는 적용 범위에 해당합니다. '기본' 규칙에는 예측조건이 없습니다. 이러한 앵커들은 모형이 예측의 온도를 주로 고려한다는 것을 보여줍니다.</i>
</p>

결과는 직관적으로 해석할 수 있고 설명된 각 관측치에 대해 모델의 예측에 가장 중요한 특성이 무엇인지 보여줍니다. 앵커에는 몇 개의 예측조건만 있으므로, 추가로 적용 범위가 넓어 다른 사례에도 적용됩니다.
위에 표시된 규칙은 $$\tau = 0.9$$로 생성되었습니다. 따라서 평가된 perturbation가 최소 90%의 정확도로 라벨을 충실히 지원하는 앵커를 구합니다. 또한, 연속형 특성의 표현성과 적용성을 높이기 위해 범주화 하였습니다.

이전 규칙은 모두 모델이 몇 가지 특성을 기반으로 자신 있게 결정하는 경우에 대해 생성되었습니다. 그러나 다른 관측치는 더 많은 특성이 중요하기 때문에 모델별로 명확하게 분류되지 않습니다. 이러한 경우 앵커가 더 구체화되고 더 많은 특성을 구성하며 더 적은 관측치에 적용됩니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/unnamed-chunk-26-1.png'><br>
    <i>그림 5.40: 의사 결정 경계에 가까운 예를 설명하면 더 많은 수의 특성 예측조건와 더 좁은 적용 범위로 구성된 특정 규칙이 나타납니다. 또한 빈 규칙, 즉 기본 특성은 덜 중요해집니다. 이는 관측치가 휘발성이 강한 이웃에 있으므로 의사 결정 경계의 신호로 해석할 수 있습니다.</i>
</p>

기본 perturbation 공간을 선택하는 것은 편안한 선택이지만 알고리즘에 큰 영향을 미칠 수 있으므로 편향된 결과를 초래할 수 있습니다. 예를 들어, 학습 세트의 균형이 맞지 않는 경우(각 클래스의 관측치 수가 같지 않음), perturbation 공간도 마찬가지입니다. 이 상태는 규칙 검색 및 결과의 정밀도에 더 영향을 미칩니다.

[자궁경부암](https://tootouch.github.io/IML/cervical_cancer/) 데이터 세트는 이러한 상황의 훌륭한 예입니다. 앵커 알고리즘을 적용하면 다음 상황 중 하나로 이어집니다.

- *건강*이라고 표시된 관측치를 설명하면 생성된 모든 이웃이 *건강*으로 평가하므로 빈 규칙이 생성됩니다.
- *암*이라고 표시된 관측치에 대한 설명은 지나치게 구체적입니다. 즉, perturbation 공간은 대부분 *건강* 관측치의 값을 포함하기 때문에 여러 가지 특성 예측조건로 구성됩니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/unnamed-chunk-29-1.png'><br>
    <i>그림 5.41: 불균형 perturbation 공간 내에 앵커를 구성하면 설명하기 힘든 결과가 발생합니다.</i>
</p>

이 결과는 원치 않을 수 있으며 여러 가지 방법으로 접근될 수 있습니다. 예를 들어, 불균형 데이터 세트 또는 정규 분포와 같이 표본이 서로 다르게 샘플링되는 사용자 정의 perturbation 공간을 정의할 수 있습니다. 그러나, 이는 다음과 같은 부작용이 있습니다. 샘플링된 이웃들은 대표적이지 않고 적용 범위의 크기를 바꿉니다. 또는 MAB의 신뢰도 $$\delta$$ 및 오류 파라미터 값 $$\epsilon$$을(를) 수정할 수 있습니다. 이렇게 하면 MAB가 더 많은 샘플을 채취하게 되고, 결과적으로 소수들이 절대적으로 더 자주 샘플링됩니다.

이 예에서는 대부분의 경우 *암*이라고 표시된 자궁경부암 데이터의 부분집합을 사용합니다. 그렇다면 이제 우리는 그것으로부터 상응하는 perturbation 공간을 만들 수 있는 프레임워크를 가지게 됩니다. 이제 perturbation은 다양한 예측으로 이어질 가능성이 높으며 앵커 알고리즘은 중요한 함수을 식별할 수 있습니다. 하지만, 사람들은 범위의 정의를 고려해야 합니다. 이는 perturbation 공간 안에서만 정의됩니다. 앞의 예에서는 학습 세트를 perturbation 공간의 기준으로 사용했습니다. 여기서는 하위 집합만 사용하기 때문에 넓은 적용 범위가 글로벌하게 높은 규칙의 중요성을 나타내는 것은 아닙니다.

<p align='center'>
    <img src='https://christophm.github.io/interpretable-ml-book/images/unnamed-chunk-30-1.png'><br>
    <i>그림 5.42: 앵커를 구성하기 전에 데이터 집합의 균형을 맞추는 것은 소수의 경우 결정에 대한 모델의 추론을 보여줍니다.</i>
</p>


# 장점

앵커 접근방식은 LIME에 비해 여러 가지 장점을 제공합니다. 첫째, **규칙이 해석하기 쉽기 때문에 (일반인도 포함)** 알고리즘의 결과를 이해하기 쉽습니다.

또한 **앵커는 하위 테이블**이며, 범위 개념을 포함함으로써 중요도를 측정합니다. 둘째, **앵커는 모델 예측이 관측치에서 비선형적이거나 복잡한 경우**에도 사용할 수 있습니다. 이 접근 방식은 대체 모델을 장착하는 대신 강화 학습 기법을 구현하기 때문에 모델에 적합하지 않을 가능성이 낮습니다.

이와는 별도로 알고리즘은 **model-agnostic**이므로 모든 모델에 적용할 수 있습니다.

또한 배치 샘플링을 지원하는 MAB(예: BatchSAR)를 사용하여 **병렬처리 할 수 있으므로** 고효율적입니다.

# 단점

이 알고리즘은 대부분의 perturbation 기반 설명과 마찬가지로 **아주 구체적이고** 및 영향력 있는 설정으로 인해 어려움을 겪습니다. 빔 너비 또는 정밀도 임계값과 같은 하이퍼 파라미터는 의미 있는 결과를 도출하기 위해 튜닝되어야 할 뿐만 아니라, perturbation 함수을 하나의 도메인/사용 사례에 맞게 명시적으로 설계해야 합니다. 표 형식의 데이터가 어떻게 perturbation되는지 생각해 보고 이미지 데이터에 동일한 개념을 적용하는 방법을 생각해 봅니다(힌트: 이 개념을 적용할 수 없음). 다행히도 일부 도메인(예: 표)에서 기본 접근 방식을 사용하여 초기 설명 설정을 용이하게 할 수 있습니다.

또한 많은 시나리오에서는 결과가 너무 구체적이고 적용 범위가 낮으며 모델을 이해하는 데 기여하지 않으므로의 **범주화가 필요합니다**. 범주화가 도움이 될 수 있지만 부주의하게 사용할 경우 의사결정 경계를 흐리게 하여 정반대의 효과를 가져올 수도 있습니다. 최상의 범주화 기법이 없기 때문에, 사용자는 나쁜 결과를 얻지 않도록 데이터를 범주화하는 방법을 결정하기 전에 데이터를 알아야 합니다.

앵커를 구성하려면 모든 perturbation 기반 설명과 마찬가지로 **ML 모델에 대한 많은 호출이 필요합니다**. 알고리즘은 호출 수를 최소화하기 위해 MAB를 적용하지만, 여전히 실행 시간은 모델의 성능에 따라 크게 달라지기 때문에 매우 가변적입니다.

마지막으로 일부 도메인에서는 **범위 개념이 정의되지 않았습니다**. 예를 들어, 한 이미지의 슈퍼픽셀이 다른 이미지의 슈퍼픽셀과 어떻게 비교되는지에 대한 명확하거나 보편적인 정의는 없습니다.

# 소프트웨어 및 대안책

현재 [앵커, Python 패키지](https://github.com/marcotcr/anchor)([Alibi](https://github.com/SeldonIO/alibi)로 통합됨)와 [Java 구현](https://github.com/viadee/javaAnchorExplainer)의 두 가지 구현체를 사용할 수 있습니다. 
전자는 앵커 알고리즘의 저자의 참조이며 후자는 본 장의 예에 사용된 [앵커](https://github.com/viadee/anchorsOnR)라는 R 인터페이스와 함께 제공되는 고성능 구현입니다.
현재 앵커는 표 데이터만 지원합니다. 그러나 이론적으로 모든 도메인 또는 데이터 유형에 대해 앵커를 구성할 수 있습니다.

---

[^1]: Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin. "Anchors: High-Precision Model-Agnostic Explanations." AAAI Conference on Artificial Intelligence (AAAI), 2018

[^2]: Emilie Kaufmann and Shivaram Kalyanakrishnan. “Information Complexity in Bandit Subset Selection”. Proceedings of Machine Learning Research (2013).